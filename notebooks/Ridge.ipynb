{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c07aba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import faker\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import Ridge as RidgeRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "050dd596",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def random_ll_game(bet_size=1500, win=.38925, push=0.3):\n",
    "    \n",
    "\n",
    "#     res = np.random.random()\n",
    "#     if res < win:\n",
    "#         return 0.94*bet_size\n",
    "#     elif res < win+push:\n",
    "#         return 0*bet_size\n",
    "    \n",
    "#     else:\n",
    "#         return -1*bet_size\n",
    "    \n",
    "#     return\n",
    "\n",
    "# def random_hl_game(bet_size=10000, win=0.384, push=0.3):\n",
    "    \n",
    "#     res = np.random.random()\n",
    "#     if res < win:\n",
    "#         return 0.94\n",
    "#     elif res < win+push:\n",
    "#         return 0\n",
    "    \n",
    "#     else:\n",
    "#         return -1\n",
    "    \n",
    "    \n",
    "#     return\n",
    "\n",
    "# go_bust = []\n",
    "# finals = []\n",
    "# for sim in tqdm(range(5000)):\n",
    "#     bankroll = 100000\n",
    "#     has_gone_bust = False\n",
    "#     for i in range(6):\n",
    "#         for ll in range(400):\n",
    "#             delta = random_ll_game(1500)\n",
    "#             bankroll+=delta\n",
    "#             if ((bankroll<0)&(not has_gone_bust)):\n",
    "#                 has_gone_bust=True\n",
    "#         for total in range(200):\n",
    "#             delta = random_hl_game(10000)\n",
    "#             bankroll+=delta\n",
    "#             if ((bankroll<0)&(not has_gone_bust)):\n",
    "#                 has_gone_bust=True\n",
    "#         for side in range(200):\n",
    "#             delta = random_hl_game(5000)\n",
    "#             bankroll+=delta\n",
    "#             if ((bankroll<0)&(not has_gone_bust)):\n",
    "#                 has_gone_bust=True\n",
    "#     for i in range(6):\n",
    "#         for ll in range(400):\n",
    "#             delta = random_ll_game(3000)\n",
    "#             bankroll+=delta\n",
    "#             if ((bankroll<0)&(not has_gone_bust)):\n",
    "#                 has_gone_bust=True\n",
    "#         for total in range(200):\n",
    "#             delta = random_hl_game(20000)\n",
    "#             bankroll+=delta\n",
    "#             if ((bankroll<0)&(not has_gone_bust)):\n",
    "#                 has_gone_bust=True\n",
    "#         for side in range(200):\n",
    "#             delta = random_hl_game(10000)\n",
    "#             bankroll+=delta\n",
    "#             if ((bankroll<0)&(not has_gone_bust)):\n",
    "#                 has_gone_bust=True\n",
    "#     if has_gone_bust:\n",
    "#         go_bust.append(1)\n",
    "#     else:\n",
    "#         go_bust.append(0)\n",
    "#     finals.append(bankroll)\n",
    "        \n",
    "        \n",
    "# np.mean(finals)\n",
    "# np.std(finals)\n",
    "# np.sum(go_bust)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1cfaff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_fake_Ridge_ratings(num_players, mean=0, std_dev=3):\n",
    "    \n",
    "    \"\"\"Create fake Ridge ratings for a given number of players.\"\"\"\n",
    "\n",
    "    fake = faker.Faker()\n",
    "    rtg_dict = {}\n",
    "    ratings = np.random.normal(mean, std_dev, num_players)\n",
    "    for i in range(num_players):\n",
    "        rtg_dict[fake.name()] = ratings[i]\n",
    "\n",
    "    return rtg_dict\n",
    "\n",
    "def create_Ridge_random_walk(player_rating_dict, num_rounds=250, step_size=0.1, matchup_std_dev=8, stat='break_dancing'):\n",
    "    \n",
    "    \"\"\"Create a random walk of Ridge ratings, given some ratings.\"\"\"\n",
    "\n",
    "    assert(num_rounds>=1)\n",
    "    names = list(player_rating_dict.keys())\n",
    "\n",
    "    data_random_walk = []\n",
    "    for rnd in range(1, num_rounds+1):\n",
    "        rnd_set = set(copy(names))\n",
    "        while len(rnd_set)>=2:\n",
    "            player_a = random.choice(list(rnd_set))\n",
    "            rnd_set.remove(player_a)\n",
    "            player_b = random.choice(list(rnd_set))\n",
    "            rnd_set.remove(player_b)\n",
    "            data_random_walk.append([player_a, player_b, rnd, player_rating_dict[player_a], player_rating_dict[player_b]])\n",
    "        \n",
    "        for player in names:\n",
    "            nudge = step_size*2*(np.random.random()-0.5)\n",
    "            rtg  = player_rating_dict[player]\n",
    "            \n",
    "            \n",
    "            rtg = np.max([1, rtg+nudge])\n",
    "            player_rating_dict[player] = rtg\n",
    "            \n",
    "    data_random_walk = pd.DataFrame(data_random_walk, columns=['player_a','player_b','rating_period', 'player_a_true','player_b_true'])\n",
    "    data_random_walk = data_random_walk.sort_values(by=['rating_period','player_a']).reset_index(drop=True)\n",
    "    data_random_walk['true_matchup_mean'] = data_random_walk.apply(lambda x: x.player_a_true - x.player_b_true, axis=1)\n",
    "    data_random_walk['true_matchup_std_dev'] = matchup_std_dev\n",
    "    data_random_walk['result'] = data_random_walk.apply(lambda x: np.random.normal(x.true_matchup_mean, x.true_matchup_std_dev), axis=1)\n",
    "\n",
    "    ## need reverse\n",
    "    reverse = data_random_walk.copy()\n",
    "\n",
    "    reverse = reverse.rename(columns={\n",
    "        'player_a':'player_b',\n",
    "        'player_b':'player_a',\n",
    "        'player_a_true':'player_b_true',\n",
    "        'player_b_true':'player_a_true'\n",
    "    })\n",
    "\n",
    "    reverse['true_matchup_mean'] = -1*reverse['true_matchup_mean'].copy()\n",
    "    reverse['result'] = -1*reverse['result'].copy()\n",
    "\n",
    "    data_random_walk = pd.concat([data_random_walk, reverse], axis=0).sort_values(by=['rating_period','player_a']).reset_index(drop=True)\n",
    "    data_random_walk['rating_period'] = data_random_walk['rating_period'].astype(int)\n",
    "    data_random_walk['stat'] = stat\n",
    "    \n",
    "    return data_random_walk\n",
    "\n",
    "player_ratings = create_fake_Ridge_ratings(24)\n",
    "ridge_random_walk = create_Ridge_random_walk(player_ratings)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0dcb281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RidgeRating():\n",
    "\n",
    "    \"\"\"\n",
    "    Implements ranking system that uses ridge regression to estimate mean player/team ratings.\n",
    "\n",
    "        Parameters\n",
    "    ----------\n",
    "    data : pandas dataframe\n",
    "        Dataframe containing the following columns:\n",
    "            - protag_id: id of protagonist (player or team)\n",
    "            - antag_id: id of antagonist (player or team)\n",
    "            - stat: name of stat\n",
    "            - result: 0 for loss, 1 for win, 0.5 for tie\n",
    "            - is_home (optional): 1 for home, -1 for away, 0 for neutral\n",
    "            - date: date of game\n",
    "            - rating_period (if no date): rating period of game \n",
    "    alpha : float\n",
    "        Regularization parameter for ridge regression. The default is 1.0.\n",
    "    decay_type : str\n",
    "        Type of decay to use. Either 'date' or 'rating_period'. The default is 'date'.\n",
    "    decay_function : function\n",
    "        Function that takes a time delta and returns a decay factor. The default is lambda x: 1.0.\n",
    "    protag_id : str, optional\n",
    "        Name of protagonist id column in data. The default is 'team_name'.\n",
    "    antag_id : str, optional\n",
    "        Name of antagonist id column in data. The default is 'opp_name'.\n",
    "    result_col : str, optional\n",
    "        Name of result column in data. The default is 'result'.\n",
    "    priors : dict, optional\n",
    "        Dictionary of prior ratings to use for each stat. Keys are protag_ids, values are dicts of stat:rating pairs. The default is None.  \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, alpha, decay_type, decay_function, protag_id='player_a', antag_id='player_b', result_col='result', priors=None):\n",
    "\n",
    "        data.columns=[x.lower().strip() for x in data.columns]\n",
    "\n",
    "        self.data = data\n",
    "        assert(isinstance(self.data, pd.DataFrame)), \"data is not a pandas dataframe\"\n",
    "        self.alpha = alpha\n",
    "        assert(isinstance(self.alpha, float)), \"alpha is not a float\"\n",
    "        self.decay_type = decay_type\n",
    "        assert(decay_type in ['date','rating_period']), \"decay_type is not 'date' or 'rating_period'\"\n",
    "        if decay_type == 'date':\n",
    "            assert('date' in self.data.columns), \"data does not contain a date column\"\n",
    "            assert(is_datetime(self.data['date'])), \"date column is not a datetime\"\n",
    "            self.period_col = 'date'\n",
    "        elif decay_type == 'rating_period':\n",
    "            assert('rating_period' in self.data.columns), \"data does not contain a rating_period column\"\n",
    "            assert(self.data['rating_period'].dtype == int), \"rating_period column is not an int\"\n",
    "            self.period_col = 'rating_period'\n",
    "        self.decay_function = decay_function\n",
    "        assert(callable(self.decay_function)), \"decay_function is not a function\"\n",
    "        self.protag_id = protag_id\n",
    "        assert(isinstance(self.protag_id, str)), \"protag_id is not a string\"\n",
    "        self.antag_id = antag_id\n",
    "        assert(isinstance(self.antag_id, str)), \"antag_id is not a string\"\n",
    "        self.result_col = result_col\n",
    "        assert(isinstance(self.result_col, str)), \"result_col is not a string\"\n",
    "        self.priors = priors\n",
    "        assert(isinstance(self.priors, dict) or self.priors is None), \"priors is not a dict or None\"\n",
    "\n",
    "        if (('is_home' not in self.data.columns) and ('hfa' not in self.data.columns)):\n",
    "            print(\"Warning: no is_home or home field advantage ('hfa') column found in data. Assuming all games are neutral site.\")\n",
    "            self.data['is_home'] = 0\n",
    "\n",
    "        assert('stat' in self.data.columns), \"data does not contain a stat column\"\n",
    "        self.stats = list(self.data['stat'].unique())\n",
    "        assert(len(self.stats)>0), \"data does not contain any stats\"\n",
    "        assert([isinstance(x, str) for x in self.stats]), \"stats are not strings\"\n",
    "\n",
    "        ### useful meta information\n",
    "        self.num_stats = len(self.stats)\n",
    "        self.protag_ids = list(self.data[self.protag_id].unique())\n",
    "        self.num_protags = len(self.protag_ids)\n",
    "        self.num_games = len(self.data)//2\n",
    "\n",
    "        ### check if data is symmetrical, i.e., for every team a vs team b there is a team b vs team a\n",
    "        protags = self.data.groupby(['rating_period','stat'])[self.protag_id].apply(set).reset_index().copy()\n",
    "        antags =self.data.groupby(['rating_period','stat'])[self.antag_id].apply(set).reset_index().copy()\n",
    "        sym_test = protags.merge(antags, how='left', on=['rating_period','stat'])\n",
    "        sym_test['sym_diff'] = sym_test[[self.protag_id,self.antag_id]].apply(lambda x: len(x[self.protag_id].symmetric_difference(x[self.antag_id])), axis=1)\n",
    "        sym_val = sym_test['sym_diff'].mean()\n",
    "    \n",
    "        if sym_val > 0.05:\n",
    "            print(\"Warning: data is not symmetrical. There should be two rows per match for this class\")\n",
    "            raise ValueError(\" At least {}% of games are missing.\".format(round(100*sym_val,2)))\n",
    "        elif sym_val > 0:\n",
    "            print(\"Warning: a few games are likely missing their symmetrical partner.\")\n",
    "\n",
    "\n",
    "    def optimize(self):\n",
    "\n",
    "        return\n",
    "    \n",
    "    def date_history(self):\n",
    "\n",
    "        unique_periods = self.data.date.unique()\n",
    "\n",
    "        pregame_ratings = []\n",
    "        for unique_period in tqdm(unique_periods):\n",
    "            prev_history = self.data[self.data.date<unique_date].copy()\n",
    "            team_ohe = OneHotEncoder()\n",
    "            opp_ohe = OneHotEncoder()\n",
    "            team_ohe.fit(prev_history[self.protag_id].values.reshape(-1,1))\n",
    "            opp_ohe.fit(prev_history[self.antag_id].values.reshape(-1,1))\n",
    "            team_one_hot = team_ohe.transform(prev_history[self.protag_id].values.reshape(-1,1)).toarray()\n",
    "            opp_one_hot = opp_ohe.transform(prev_history[self.antag_id].values.reshape(-1,1)).toarray()\n",
    "            if 'hfa' not in prev_history.columns:\n",
    "                is_home = prev_history['is_home'].values.reshape(-1,1)\n",
    "            else:\n",
    "                is_home = prev_history['hfa'].values.reshape(-1,1)\n",
    "\n",
    "            X = np.concatenate([team_one_hot, opp_one_hot, is_home], axis=1)\n",
    "            y = prev_history[self.result_col].values.reshape(-1,1)\n",
    "            ridge = RidgeRegression(alpha=self.alpha)\n",
    "            ridge.fit(X,y)\n",
    "\n",
    "            protag_names = team_ohe.get_feature_names()\n",
    "            antag_names = opp_ohe.get_feature_names()\n",
    "            protag_map = {pn:ridge.coef_[0][i] for i,pn in enumerate(protag_names)}\n",
    "            antag_map = {an:ridge.coef_[0][len(protag_names)+i] for i,an in enumerate(antag_names)}\n",
    "\n",
    "            to_append = self.data[['protag_id','antag_id','is_home','result','stat','date']][self.data.date==unique_date].copy()\n",
    "            to_append['protag_rating'] = to_append['protag_id'].apply(lambda x: protag_map.get(x))\n",
    "            to_append['antag_rating'] = to_append['antag_id'].apply(lambda x: antag_map.get(x))\n",
    "\n",
    "            pregame_ratings.append(to_append)\n",
    "        \n",
    "        pregame_ratings = pd.concat(pregame_ratings, axis=0)\n",
    "        pregame_ratings = pregame_ratings.sort_values(by=['date',self.protag_id]).reset_index(drop=True)\n",
    "\n",
    "        return pregame_ratings\n",
    "    \n",
    "    def run_history(self):\n",
    "\n",
    "        self.data = self.data.sort_values(by=[self.period_col,self.protag_id]).reset_index(drop=True)\n",
    "        self.data['decay'] = self.data[self.period_col].apply(self.decay_function)\n",
    "\n",
    "        null_decays = self.data.decay.isnull().sum()/len(self.data)\n",
    "        if null_decays > 0:\n",
    "            print(\"Warning: {}% of games have no decay factor.\".format(round(100*null_decays,2)))\n",
    "            print(\"         Setting decay factor to 0.\")\n",
    "        self.data['decay'] = self.data['decay'].fillna(0)\n",
    "\n",
    "        unique_periods = self.data[self.period_col].unique()\n",
    "\n",
    "        pregame_ratings = []\n",
    "        for unique_period in tqdm(unique_periods[1:]):\n",
    "            prev_history = self.data[self.data[self.period_col]<unique_period].copy()\n",
    "            \n",
    "            team_ohe = OneHotEncoder()\n",
    "            opp_ohe = OneHotEncoder()\n",
    "            team_ohe.fit(prev_history[self.protag_id].values.reshape(-1,1))\n",
    "            opp_ohe.fit(prev_history[self.antag_id].values.reshape(-1,1))\n",
    "            team_one_hot = team_ohe.transform(prev_history[self.protag_id].values.reshape(-1,1)).toarray()\n",
    "            opp_one_hot = opp_ohe.transform(prev_history[self.antag_id].values.reshape(-1,1)).toarray()\n",
    "            if 'hfa' not in prev_history.columns:\n",
    "                is_home = prev_history['is_home'].values.reshape(-1,1)\n",
    "            else:\n",
    "                is_home = prev_history['hfa'].values.reshape(-1,1)\n",
    "\n",
    "            X = np.concatenate([team_one_hot, opp_one_hot, is_home], axis=1)\n",
    "            y = prev_history[self.result_col].values.reshape(-1,1)\n",
    "            ridge = RidgeRegression(alpha=self.alpha)\n",
    "            ridge.fit(X,y)\n",
    "\n",
    "            protag_names = team_ohe.get_feature_names_out()\n",
    "            ## strip x0_ from names\n",
    "            protag_names = [x[3:] for x in protag_names]\n",
    "            antag_names = opp_ohe.get_feature_names_out()\n",
    "            ## strip x0_ from names\n",
    "            antag_names = [x[3:] for x in antag_names]\n",
    "            protag_map = {pn:ridge.coef_[0][i] for i,pn in enumerate(protag_names)}\n",
    "            antag_map = {an:ridge.coef_[0][len(protag_names)+i] for i,an in enumerate(antag_names)}\n",
    "\n",
    "            to_append = self.data[[self.protag_id,self.antag_id,'is_home',self.result_col,'stat',self.period_col]][self.data[self.period_col]==unique_period].copy()\n",
    "            to_append['protag_rating'] = to_append[self.protag_id].apply(lambda x: protag_map.get(x))\n",
    "            to_append['antag_rating'] = -1*to_append[self.antag_id].apply(lambda x: antag_map.get(x))\n",
    "\n",
    "            pregame_ratings.append(to_append)\n",
    "        \n",
    "        pregame_ratings = pd.concat(pregame_ratings, axis=0)\n",
    "        pregame_ratings = pregame_ratings.sort_values(by=[self.period_col,self.protag_id]).reset_index(drop=True)\n",
    "\n",
    "        return pregame_ratings\n",
    "    \n",
    "    def update(self):\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a588dfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 249/249 [00:01<00:00, 242.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_a</th>\n",
       "      <th>player_b</th>\n",
       "      <th>is_home</th>\n",
       "      <th>result</th>\n",
       "      <th>stat</th>\n",
       "      <th>rating_period</th>\n",
       "      <th>protag_rating</th>\n",
       "      <th>antag_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andre Hall</td>\n",
       "      <td>Diana Morris</td>\n",
       "      <td>0</td>\n",
       "      <td>6.361305</td>\n",
       "      <td>break_dancing</td>\n",
       "      <td>2</td>\n",
       "      <td>3.224333</td>\n",
       "      <td>8.454275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blake Scott</td>\n",
       "      <td>Michael Carrillo</td>\n",
       "      <td>0</td>\n",
       "      <td>2.886788</td>\n",
       "      <td>break_dancing</td>\n",
       "      <td>2</td>\n",
       "      <td>3.944387</td>\n",
       "      <td>7.179638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christopher Smith</td>\n",
       "      <td>Kelly Curry</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.858057</td>\n",
       "      <td>break_dancing</td>\n",
       "      <td>2</td>\n",
       "      <td>-5.606379</td>\n",
       "      <td>-1.011293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Danny Mayer</td>\n",
       "      <td>Mitchell King</td>\n",
       "      <td>0</td>\n",
       "      <td>13.535308</td>\n",
       "      <td>break_dancing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.011293</td>\n",
       "      <td>4.013202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>David Anderson</td>\n",
       "      <td>Phillip Higgins</td>\n",
       "      <td>0</td>\n",
       "      <td>5.229161</td>\n",
       "      <td>break_dancing</td>\n",
       "      <td>2</td>\n",
       "      <td>-3.944387</td>\n",
       "      <td>-8.347246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            player_a          player_b  is_home     result           stat  \\\n",
       "0         Andre Hall      Diana Morris        0   6.361305  break_dancing   \n",
       "1        Blake Scott  Michael Carrillo        0   2.886788  break_dancing   \n",
       "2  Christopher Smith       Kelly Curry        0  -4.858057  break_dancing   \n",
       "3        Danny Mayer     Mitchell King        0  13.535308  break_dancing   \n",
       "4     David Anderson   Phillip Higgins        0   5.229161  break_dancing   \n",
       "\n",
       "   rating_period  protag_rating  antag_rating  \n",
       "0              2       3.224333      8.454275  \n",
       "1              2       3.944387      7.179638  \n",
       "2              2      -5.606379     -1.011293  \n",
       "3              2       1.011293      4.013202  \n",
       "4              2      -3.944387     -8.347246  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decay_func(days_ago):\n",
    "    return 1/(np.exp(days_ago/365))\n",
    "ridge = RidgeRating(ridge_random_walk, 0.05, 'rating_period', decay_func)\n",
    "\n",
    "pregame_ratings = ridge.run_history()\n",
    "pregame_ratings.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4864125f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_home</th>\n",
       "      <th>result</th>\n",
       "      <th>rating_period</th>\n",
       "      <th>protag_rating</th>\n",
       "      <th>antag_rating</th>\n",
       "      <th>player_a_true</th>\n",
       "      <th>player_b_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_home</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.147</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.205</td>\n",
       "      <td>-0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rating_period</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protag_rating</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>antag_rating</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_a_true</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>player_b_true</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.027</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-0.040</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               is_home  result  rating_period  protag_rating  antag_rating  \\\n",
       "is_home            NaN     NaN            NaN            NaN           NaN   \n",
       "result             NaN   1.000          0.000          0.147        -0.147   \n",
       "rating_period      NaN   0.000          1.000          0.000        -0.000   \n",
       "protag_rating      NaN   0.147          0.000          1.000         0.026   \n",
       "antag_rating       NaN  -0.147         -0.000          0.026         1.000   \n",
       "player_a_true      NaN   0.205          0.097          0.785        -0.027   \n",
       "player_b_true      NaN  -0.205          0.097         -0.027         0.785   \n",
       "\n",
       "               player_a_true  player_b_true  \n",
       "is_home                  NaN            NaN  \n",
       "result                 0.205         -0.205  \n",
       "rating_period          0.097          0.097  \n",
       "protag_rating          0.785         -0.027  \n",
       "antag_rating          -0.027          0.785  \n",
       "player_a_true          1.000         -0.040  \n",
       "player_b_true         -0.040          1.000  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test = pregame_ratings.merge(ridge_random_walk[['player_a','player_b','rating_period','player_a_true','player_b_true']], how='left', on=['player_a','player_b','rating_period'])\n",
    "test.corr().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "468fcf4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945355327605971"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "decay_func(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28804a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28587f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d17a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f17e68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Elo():\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Implements classic Elo algorithm for a single stat or multiple stats simultaneously\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas dataframe\n",
    "        Dataframe containing the following columns:\n",
    "            - protag_id: id of protagonist (player or team)\n",
    "            - antag_id: id of antagonist (player or team)\n",
    "            - stat: name of stat\n",
    "            - result: 0 for loss, 1 for win, 0.5 for tie\n",
    "            - is_home (optional): 1 for home, -1 for away, 0 for neutral\n",
    "            - date: date of game\n",
    "            - rating_period (if no date): rating period of game \n",
    "    k : int, float, or dict\n",
    "        Elo k value(s) to use for each stat. If int or float, applies to all stats. If dict, keys must be stat names, values are k values for each stat\n",
    "    hfa : int, float, or dict\n",
    "        Home field advantage value(s) to use for each stat. If int or float, applies to all stats. If dict, keys must be stat names, values are hfa values for each stat\n",
    "    protag_id : str, optional\n",
    "        Name of protagonist id column in data. The default is 'team_name'.\n",
    "    antag_id : str, optional\n",
    "        Name of antagonist id column in data. The default is 'opp_name'.\n",
    "    result_col : str, optional\n",
    "        Name of result column in data. The default is 'result'.\n",
    "    priors : dict, optional\n",
    "        Dictionary of prior ratings to use for each stat. Keys are protag_ids, values are dicts of stat:rating pairs. The default is None.      \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, \n",
    "                 data, \n",
    "                 k,\n",
    "                 hfa=None,\n",
    "                 protag_id='team_name', \n",
    "                 antag_id='opp_name',\n",
    "                 result_col='result',\n",
    "                 priors = None\n",
    "                ):\n",
    "        \n",
    "        self.data = data.copy()\n",
    "        self.protag_id = protag_id\n",
    "        self.antag_id = antag_id\n",
    "\n",
    "        assert(self.protag_id in list(data)), f\"{self.protag_id} not in columns, please specify team column name with protag_id argument\"\n",
    "        assert(self.antag_id in list(data)), f\"{self.antag_id} not in columns, please specify opponent column name with antag_id argument\"\n",
    "\n",
    "        assert('stat' in list(self.data)), 'No stat column, please add a stat name column to your data'\n",
    "        self.stats = sorted(list(self.data.stat.unique()))\n",
    "        self.result_col = result_col\n",
    "        assert(self.result_col in list(self.data)), 'Please include an outcome/result column, can specify the name with result col argument'\n",
    "        self.priors = priors\n",
    "        \n",
    "        ## initialize k and hfa as None to help _add methods know it is still initializing\n",
    "        self.k = None\n",
    "        self._add_k(k)\n",
    "\n",
    "        self.hfa = None\n",
    "        self._add_hfa(hfa)\n",
    "        \n",
    "        ### check if results are in binary format (or tie)\n",
    "        results = list(self.data[self.result_col].unique())\n",
    "        assert(all([(np.isclose(r,0)|(np.isclose(r,1)|(np.isclose(r,0.5)))) for r in results])), \"Results must be zero (for loss) or one (for win) or 0.5 (for tie)\"\n",
    "\n",
    "        ## add rating period if only date is provided\n",
    "        self._add_rating_period()\n",
    "        \n",
    "        ### initialize rating tracking and ids\n",
    "        self.protag_ids = set(self.data[self.protag_id].unique())\n",
    "        self.antag_ids = set(self.data[self.antag_id].unique())\n",
    "        \n",
    "        assert(len(self.protag_ids.symmetric_difference(self.antag_ids))==0), \"In SPR format, need a row for each team in dataframe (two rows per game)\"\n",
    "        \n",
    "        ### useful meta information\n",
    "        self.num_stats = len(self.stats)\n",
    "        self.num_protags = len(self.protag_ids)\n",
    "        self.num_games = len(self.data)//2\n",
    "        \n",
    "        ### index maps\n",
    "        self.protag2index = {}\n",
    "        for i,protag_id in enumerate(self.protag_ids):\n",
    "            self.protag2index[protag_id] = i\n",
    "            \n",
    "        self.stat2index = {}\n",
    "        for j,stat in enumerate(self.stats):\n",
    "            self.stat2index[stat] = j\n",
    "            \n",
    "        ### initialize ratings\n",
    "        self.data['protag_idx'] = self.data[self.protag_id].copy().map(self.protag2index)\n",
    "        self.data['antag_idx'] = self.data[self.antag_id].copy().map(self.protag2index)\n",
    "        self.data['stat_idx'] = self.data['stat'].copy().map(self.stat2index)\n",
    "        self.data['hfa'] = self.data['stat'].copy().map(self.hfa).copy()*self.data['is_home'].copy()\n",
    "        assert(len(self.data.loc[self.data.hfa.isnull()])==0), f\"{self.data.loc[self.data.hfa.is_null()].stat.unique()} do not have a home field advantage number\"\n",
    "        \n",
    "        self.history = \"Use .run_history() to create history\"\n",
    "        \n",
    "        self.reset_ratings_mat()\n",
    "\n",
    "        return\n",
    "    \n",
    "    def reset_ratings_mat(self):\n",
    "\n",
    "        self.rating_matrix = np.ones((self.num_protags, self.num_stats))*1500\n",
    "        \n",
    "        ### add priors for those specified\n",
    "        ### priors must be a dict in form of {protag_id:{stat:rating}}\n",
    "        if self.priors is not None:\n",
    "            assert(type(self.priors)==dict), \"Priors must be a dict\"\n",
    "            for protag_id, stat_dict in self.priors.items():\n",
    "                assert(type(stat_dict)==dict), \"Each protag_id key in priors dict must be a dict of stat:rating pairs\"\n",
    "                for stat, rating in stat_dict.items():\n",
    "                    assert(stat in self.stats), f\"{stat} is not a stat in the dataset\"\n",
    "                    self.rating_matrix[self.protag2index[protag_id], self.stat2index[stat]] = rating\n",
    "        return\n",
    "    \n",
    "    def _add_k(self, k=None, data=None):\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        Adds k to self.data if none is passed, otherwise adds k to passed data\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        ### determine format of provided k values\n",
    "        if type(k)==dict:\n",
    "            assert(key in self.stats for key in k.keys()), \"each key in k value dict must be a stat\"\n",
    "            kval_not_provided = []\n",
    "            for stat in self.stats:\n",
    "                if stat not in k:\n",
    "                    print(f\"No k value provided for {stat}, using average of other kvalues...\")\n",
    "                    kval_not_provided.append(stat)\n",
    "            self.k = k\n",
    "            for stat in kval_not_provided:\n",
    "                self.k[stat] = np.mean(self.k.values())\n",
    "                \n",
    "        elif ((isinstance(k, int))|(isinstance(k, float))):\n",
    "            self.k = {}\n",
    "            for stat in self.stats:\n",
    "                self.k[stat] = k\n",
    "        else:\n",
    "            raise ValueError(\"K values must either be a numeric (to assign to all stats) or a dict (where keys are stat names, values to be applied individually)\")\n",
    "        \n",
    "        if data is None:\n",
    "            self.data['k'] = self.data['stat'].map(self.k).copy()\n",
    "            assert(len(self.data.loc[self.data.k.isnull()])==0), f\"{self.data.loc[self.data.k.is_null()].stat.unique()} do not have a k factor specified in the k factor dict\"\n",
    "        else:\n",
    "            data['k'] = data['stat'].map(self.k).copy()\n",
    "            assert(len(data.loc[data.k.isnull()])==0), f\"{data.loc[data.k.is_null()].stat.unique()} do not have a k factor specified in the k factor dict\"\n",
    "            return data\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def _add_hfa(self, hfa=None, data=None):\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        Adds home field advantage to self.data if none is passed, otherwise adds hfa to passed data and returns it\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "        if data is None:\n",
    "            ### apply to self.data\n",
    "            ### check for home field advantage\n",
    "            if 'is_home' not in list(self.data):\n",
    "                ### if no home field advantage column, assume no home field advantage\n",
    "                self.data['is_home']=0\n",
    "                self.has_hfa = False\n",
    "            else:\n",
    "                self.has_hfa = True\n",
    "\n",
    "            locs = (self.data['is_home'].unique())\n",
    "            assert(all([(np.isclose(l,0)|(np.isclose(l,1)|(np.isclose(l,-1)))) for l in locs])), \"is_home col needs either 1 for home, -1 for away, or 0 for neutral\"\n",
    "            \n",
    "            if self.hfa is None:\n",
    "                ### determine format of provided home field advantages\n",
    "                if ((hfa is None)|(hfa==0)):\n",
    "                    self.hfa = {}\n",
    "                    for stat in self.stats:\n",
    "                        self.hfa[stat] = 0\n",
    "                elif type(hfa)==dict:\n",
    "                    assert(key in self.stats for key in hfa.keys()), \"each key in home field advantage dict must be a stat\"\n",
    "                    for stat in self.stats:\n",
    "                        if stat not in hfa:\n",
    "                            print(f\"No home field advantage provided for {stat}\")\n",
    "                    self.hfa = hfa\n",
    "                elif ((isinstance(hfa, int))|(isinstance(hfa, float))):\n",
    "                    self.hfa = {}\n",
    "                    for stat in self.stats:\n",
    "                        self.hfa[stat] = hfa\n",
    "                else:\n",
    "                    raise ValueError(\"Home field advantage must either be a numeric (to assign to all stats) or a dict (where keys are stat names, values to be applied individually)\")\n",
    "                \n",
    "        else:\n",
    "            ### apply to passed data\n",
    "            if 'is_home' not in list(data):\n",
    "                data['is_home']=0\n",
    "            if data.is_home.isnull().any():\n",
    "                data['is_home'].fillna(0, inplace=True)\n",
    "            locs = (data['is_home'].unique())\n",
    "            assert(all([(np.isclose(l,0)|(np.isclose(l,1)|(np.isclose(l,-1)))) for l in locs])), \"is_home col needs either 1 for home, -1 for away, or 0 for neutral\"\n",
    "\n",
    "        if data is None:\n",
    "            self.data['hfa'] = self.data['stat'].map(self.hfa).copy()*self.data['is_home'].copy()\n",
    "            assert(len(self.data.loc[self.data.hfa.isnull()])==0), f\"{self.data.loc[self.data.hfa.is_null()].stat.unique()} do not have a home field advantage number\"\n",
    "        else:\n",
    "            data['hfa'] = data['stat'].map(self.hfa).copy()*data['is_home'].copy()\n",
    "            assert(len(data.loc[data.hfa.isnull()])==0), f\"{data.loc[data.hfa.isnull()].stat.unique()} do not have a home field advantage number\"\n",
    "            return data\n",
    "\n",
    "        return\n",
    "    \n",
    "    def _add_rating_period(self, data=None):\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        Adds rating period to self.data if none is passed, otherwise adds rating period to passed data and returns it\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        if data is None:\n",
    "\n",
    "            ### check for rating periods or dates\n",
    "            col_names = list(self.data)\n",
    "            col_names = [cn.lower().strip() for cn in col_names]\n",
    "            assert((('date' in col_names)|('rating_period' in col_names))), \"Need either a date column or a rating period column\"\n",
    "\n",
    "            self.data.columns=col_names\n",
    "            if 'date' in col_names:\n",
    "                self.has_date = True\n",
    "                date_dtype = self.data.date.dtype\n",
    "                assert(is_datetime(date_dtype)), \"Date column must be of type datetime\"\n",
    "            else:\n",
    "                self.has_date = False\n",
    "\n",
    "            if (('date' in col_names) & ('rating_period' not in col_names)):\n",
    "                self.data['rating_period'] = self.data.date.copy().rank(method='dense')\n",
    "        else:  \n",
    "            ### check for rating periods or dates\n",
    "            col_names = list(data)\n",
    "            col_names = [cn.lower().strip() for cn in col_names]\n",
    "            assert((('date' in col_names)|('rating_period' in col_names))), \"Need either a date column or a rating period column\"\n",
    "\n",
    "            data.columns=col_names\n",
    "            if 'date' in col_names:\n",
    "                assert(self.has_date), \"Data has date column, but self.data does not\"\n",
    "                date_dtype = data.date.dtype\n",
    "                assert(is_datetime(date_dtype)), \"Date column must be of type datetime\"\n",
    "\n",
    "            if (('date' in col_names) & ('rating_period' not in col_names)):\n",
    "                data['rating_period'] = data.date.copy().rank(method='dense')\n",
    "\n",
    "            return data\n",
    "        return\n",
    "\n",
    "    \n",
    "    def _opt_helper(self, **kwargs):\n",
    "        \"\"\"\n",
    "        needed to be compatible with the optimization library\n",
    "        \"\"\"\n",
    "        k = {}\n",
    "        hfa = {}\n",
    "        \n",
    "        for key,value in kwargs.items():\n",
    "            if '_hfa' in key:\n",
    "                key_name = copy(key).replace('_hfa','') ## appended numbers to distinguish\n",
    "                hfa[key_name] = value\n",
    "            elif '_kval' in key:\n",
    "                key_name = copy(key).replace('_kval','')\n",
    "                k[key_name] = value\n",
    "            \n",
    "        if self.has_hfa:\n",
    "            _, grade = self.run_history(k=k, hfa=hfa)\n",
    "        else:\n",
    "            _, grade = self.run_history(k=k)\n",
    "        return -grade # optimizer maximizes, so need to take negative\n",
    "    \n",
    "    def _rating_period_update(self, protag_ratings, antag_ratings, k, results):\n",
    "        \"\"\"\n",
    "        performs classic Elo rating update calculation\n",
    "        \"\"\"\n",
    "        \n",
    "        probs = 1/(1+10**((antag_ratings-protag_ratings)/400))\n",
    "        return k*(results - probs)\n",
    "    \n",
    "    def _reset_ratings(self, old_data=None, priors=None):\n",
    "        \"\"\"\n",
    "        resets rating matrix to last known rating\n",
    "        \"\"\"\n",
    "        self.rating_matrix = np.ones((self.num_protags, self.num_stats))*1500\n",
    "        old_data = old_data.drop_duplicates(subset=[self.protag_id,'stat'], keep='last').copy()\n",
    "\n",
    "        old_data['protag_idx'] = old_data[self.protag_id].map(self.protag2index)\n",
    "        old_data['stat_idx'] = old_data['stat'].map(self.stat2index)\n",
    "        old_data[['protag_idx','stat_idx']] = old_data[['protag_idx','stat_idx']].astype(int)\n",
    "\n",
    "        ## merge in history\n",
    "        old_data = old_data.merge(self.history, on=['rating_period',self.protag_id,'stat'], how='left')\n",
    "\n",
    "        assert(old_data['pregame_rating'].isnull().sum()==0)\n",
    "        assert(old_data['rating_adjustment'].isnull().sum()==0)\n",
    "\n",
    "        for i,row in old_data.iterrows():\n",
    "            self.rating_matrix[row['protag_idx'], row['stat_idx']] = row['pregame_rating'] + row['rating_adjustment']\n",
    "        if priors is not None:\n",
    "            assert(type(priors)==dict), \"priors must be a dictionary\"\n",
    "            for key, value in priors.items():\n",
    "                for stat, rating in value.items():\n",
    "                    self.rating_matrix[self.protag2index[key], self.stat2index[stat]] = rating\n",
    "\n",
    "        ### reset history\n",
    "        if 'date' in list(old_data):\n",
    "            self.history = self.history.loc[self.history['date']<old_data['date'].max()].reset_index(drop=True)\n",
    "        else:\n",
    "            self.history = self.history.loc[self.history['rating_period']<old_data['rating_period'].max()].reset_index(drop=True)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def _update_rating_matrix(self, new_ids, priors=None):\n",
    "\n",
    "        \"\"\"\n",
    "        After new ids are added, need to update the rating matrix and the protag2index map\n",
    "        \"\"\"\n",
    "\n",
    "        ## update maps\n",
    "        max_index = np.max(list(self.protag2index.values()))\n",
    "        for i,new_id in enumerate(new_ids):\n",
    "            self.protag2index[new_id] = int(max_index + i + 1)\n",
    "        if len(new_ids) > 0:\n",
    "            new_ratings = np.ones((len(new_ids), self.num_stats))*1500\n",
    "            # print(f\"Old shape: {self.rating_matrix.shape}\")\n",
    "            self.rating_matrix = np.vstack((self.rating_matrix.copy(), new_ratings))\n",
    "            # print(f\"New shape: {self.rating_matrix.shape}\")\n",
    "            if priors is not None:\n",
    "                assert(type(priors)==dict), \"priors must be a dictionary\"\n",
    "                for protag_id, stat_dict in priors.items():\n",
    "                    assert(type(stat_dict)==dict), \"Each protag_id key in priors dict must be a dict of stat:rating pairs\"\n",
    "                    for stat, rating in stat_dict.items():\n",
    "                        assert(stat in self.stats), f\"{stat} is not a stat in the dataset\"\n",
    "                        self.rating_matrix[self.protag2index[protag_id], self.stat2index[stat]] = rating\n",
    "\n",
    "            else:\n",
    "                print(f\"Warning: new ids found: {new_ids}, but no priors provided. Using default priors.\")\n",
    "\n",
    "            print(\"New teams/players have been added.\")\n",
    "        assert(not np.isnan(np.sum(self.rating_matrix)))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def info(self):\n",
    "        \"\"\"\n",
    "        returns meta info, usually used right after initialization\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"There are {self.num_stats} stats: {self.stats}\")\n",
    "        print(f\"There are {self.num_protags:,} unique players/teams.\")\n",
    "        if 'date' in self.data.columns:\n",
    "            print(f\"There are {self.num_games:,} games from {self.data.date.min()} to {self.data.date.max()}.\")\n",
    "        else:\n",
    "            print(f\"There are {self.num_games:,} games over {self.data.rating_period.max()-self.data.rating_period.min()} rating periods.\")\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def current_ratings(self):\n",
    "        \"\"\"\n",
    "        returns current ratings\n",
    "        \"\"\"\n",
    "        ratings_long = self.rating_matrix.reshape(-1)\n",
    "        idx_long = np.repeat(sorted(self.protag2index.values()), self.num_stats)\n",
    "        stat_idx_long = np.tile(sorted(self.stat2index.values()), self.num_protags)\n",
    "        ratings = pd.DataFrame({\n",
    "            'protag_idx':idx_long,\n",
    "            'stat_idx':stat_idx_long,\n",
    "            'rating':ratings_long\n",
    "        })\n",
    "        self.idx2protag = {v:k for k,v in self.protag2index.items()}\n",
    "        self.idx2stat = {v:k for k,v in self.stat2index.items()}\n",
    "        ratings[self.protag_id] = ratings['protag_idx'].map(self.idx2protag)\n",
    "        ratings['stat'] = ratings['stat_idx'].map(self.idx2stat)\n",
    "        \n",
    "        return ratings.drop(columns=['protag_idx','stat_idx'])\n",
    "    \n",
    "    def run_history(self, data=None, k=None, hfa=None, metric='brier', is_update=False):\n",
    "        \"\"\"\n",
    "        calculates entire pre-game (non-leaky) ratings using current parameters\n",
    "        \n",
    "        returns: those ratings\n",
    "        \"\"\"\n",
    "        \n",
    "        assert(metric in ['brier','log_loss']), 'please use an implemented metric (brier, log_loss)' \n",
    "\n",
    "        if data is None:\n",
    "            data = self.data.copy()\n",
    "\n",
    "        if hfa is None:\n",
    "            hfa = self.hfa\n",
    "        elif type(hfa)==dict:\n",
    "            data['hfa'] = data['stat'].map(hfa).copy()\n",
    "        elif type(hfa)==int:\n",
    "            data['hfa'] = hfa\n",
    "        else:\n",
    "            raise ValueError(\"hfa must be a dictionary or an integer\")\n",
    "\n",
    "        if k is None:\n",
    "            k = self.k\n",
    "        elif type(k)==dict:\n",
    "            data['k'] = data['stat'].map(k).copy()\n",
    "        elif type(k)==int:\n",
    "            data['k'] = k\n",
    "        else:\n",
    "            raise ValueError(\"k must be a dictionary or an integer\")\n",
    "        \n",
    "        if is_update:\n",
    "            if data is None:\n",
    "                raise ValueError(\"If is_update=True, data must be provided.\")\n",
    "        else:\n",
    "            self.reset_ratings_mat()\n",
    "\n",
    "        history = []\n",
    "        quick_iterator = data.groupby(['rating_period'])\n",
    "        for rp_index, rating_period in tqdm(quick_iterator, total=len(quick_iterator)):\n",
    "            \n",
    "            # if rp_index == 1:\n",
    "            #     print(rating_period)\n",
    "\n",
    "            ## append pregame ratings to history\n",
    "            pregame_protag_ratings = self.rating_matrix[rating_period.protag_idx.values, rating_period.stat_idx.values]\n",
    "            pregame_antag_ratings = self.rating_matrix[rating_period.antag_idx.values, rating_period.stat_idx.values]\n",
    "            if self.has_date:\n",
    "                to_append = rating_period[['date','rating_period',self.protag_id,self.antag_id,'is_home','hfa','stat',self.result_col]].copy()\n",
    "            else:\n",
    "                to_append = rating_period[['rating_period',self.protag_id,self.antag_id,'is_home','hfa','stat',self.result_col]].copy()\n",
    "            to_append['pregame_rating'] = pregame_protag_ratings\n",
    "            to_append['pregame_opp_rating'] = pregame_antag_ratings\n",
    "            \n",
    "            ## account for hfa\n",
    "            pregame_protag_ratings = pregame_protag_ratings+(rating_period.hfa.values/2)\n",
    "            pregame_antag_ratings = pregame_antag_ratings-(rating_period.hfa.values/2)\n",
    "\n",
    "            rating_adjustments = self._rating_period_update(pregame_protag_ratings, pregame_antag_ratings, rating_period.k.values, rating_period[self.result_col].values)\n",
    "            \n",
    "            ## reset ratings\n",
    "            pregame_protag_ratings = pregame_protag_ratings-(rating_period.hfa.values/2)\n",
    "            pregame_antag_ratings = pregame_antag_ratings+(rating_period.hfa.values/2)\n",
    "\n",
    "            ## apply update\n",
    "            new_ratings = pregame_protag_ratings+rating_adjustments\n",
    "            to_append['rating_adjustment'] = rating_adjustments\n",
    "            \n",
    "            history.append(to_append)\n",
    "            \n",
    "            self.rating_matrix[rating_period.protag_idx.values, rating_period.stat_idx.values] = new_ratings\n",
    "\n",
    "        if is_update:\n",
    "            self.history = pd.concat([self.history, pd.concat(history, axis=0).reset_index(drop=True)], axis=0).reset_index(drop=True)\n",
    "        else:\n",
    "            self.history = pd.concat(history, axis=0).reset_index(drop=True)\n",
    "        \n",
    "        self.history['rtg_diff'] = self.history['pregame_opp_rating'].copy()-(self.history['pregame_rating'].copy()+(self.history['is_home'].copy()*self.history.hfa.values))\n",
    "        self.history['probability'] = 1/(1+10**((self.history['rtg_diff'])/400))\n",
    "        if metric == 'brier':\n",
    "            ## allow some time for ratings to stabilize\n",
    "            initial = int(0.15*len(self.history))\n",
    "\n",
    "            score = ((self.history[initial:][self.result_col].copy()-self.history[initial:]['probability'].copy())**2).mean()\n",
    "        self.history = self.history.drop(columns=['rtg_diff'])\n",
    "\n",
    "        return self.history, score\n",
    "    \n",
    "    \n",
    "    def optimize(self, \n",
    "                 init_points=10, \n",
    "                 n_iter=50, \n",
    "                 k_lower=5, \n",
    "                 k_upper=25, \n",
    "                 hfa_lower=0, \n",
    "                 hfa_upper=65, \n",
    "                 random_state=17,\n",
    "                 update_params = True\n",
    "                ):\n",
    "        \"\"\"\n",
    "        optimizes k value and home field advantage\n",
    "        \"\"\"\n",
    "        \n",
    "        pbounds = {}\n",
    "        for stat in self.stats:\n",
    "            if self.has_hfa:\n",
    "                pbounds[stat+'_hfa'] = (hfa_lower, hfa_upper)\n",
    "            pbounds[stat+'_kval'] = (k_lower, k_upper)\n",
    "            \n",
    "        self.optimizer = BayesianOptimization(\n",
    "            f=self._opt_helper,\n",
    "            pbounds=pbounds,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "        \n",
    "        self.optimizer.maximize(\n",
    "            init_points=init_points,\n",
    "            n_iter=n_iter\n",
    "        )\n",
    "        \n",
    "        print(\"\\nBest Values:\")\n",
    "        print(self.optimizer.max)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        if update_params:\n",
    "            print(\"Updating params to optimized values...\")\n",
    "            self.k = {}\n",
    "            if self.has_hfa:\n",
    "                self.hfa = {}\n",
    "            for param, value in self.optimizer.max['params'].items():\n",
    "                if '_hfa' in param:\n",
    "                    stat_name = param.replace('_hfa','')\n",
    "                    self.hfa[stat_name] = value\n",
    "                elif '_kval' in param:\n",
    "                    stat_name = param.replace('_kval','')\n",
    "                    self.k[stat_name] = value\n",
    "                    \n",
    "        gc.collect()\n",
    "        return \n",
    "    \n",
    "    def _check_for_new_ids(self, new_data, priors):\n",
    "\n",
    "        ### check for new ids\n",
    "        new_ids = set(new_data[self.protag_id].unique()).union(set(new_data[self.antag_id].unique()))\n",
    "        old_ids = self.protag_ids.union(self.antag_ids)\n",
    "        new_ids = new_ids.difference(old_ids)\n",
    "        if len(new_ids)>0:\n",
    "            print(f\"Found {len(new_ids)} new ids, adding them to the rating matrix...\")\n",
    "            self.protag_ids = self.protag_ids.union(new_ids)\n",
    "            self.antag_ids = self.antag_ids.union(new_ids)\n",
    "            self._update_rating_matrix(new_ids, priors)\n",
    "        return\n",
    "    \n",
    "    def update(self, new_data, affirm_update=False, priors=None):\n",
    "\n",
    "        if type(self.history) == str:\n",
    "            print(\"Please use run_history() function before updating with new data. Consider combining new and old data and running all at once.\")\n",
    "            return\n",
    "        \n",
    "        ### check that no new stats have been added\n",
    "        new_stats = set(new_data.stat.unique())\n",
    "        old_stats = set(self.stats)\n",
    "        new_stats = new_stats.difference(old_stats)\n",
    "        assert(len(new_stats)==0), f\"New stats found: {new_stats}. This class is not currently able to handle new stats added via update. Please re-initialize starting from beginning. Feel free to submit request to add this functionality\"\n",
    "        \n",
    "        col_names= list(new_data)\n",
    "        if 'date' in col_names:\n",
    "            ### use date\n",
    "            date_dtype = new_data.date.dtype\n",
    "            assert(is_datetime(date_dtype)), \"Date column must be of type datetime\"\n",
    "            oldest_date = new_data.date.min()\n",
    "            assert('date' in list(self.data)), \"Old data does not contain date column, new data does. Confused whether to use rating period or date.\"\n",
    "            print(f\"Oldest date in new data is {oldest_date}, starting update from that date...\")\n",
    "\n",
    "            if affirm_update:\n",
    "                print(\"Proceed, Y/N?\")\n",
    "                proceed = input()\n",
    "                if proceed.lower() not in ['y', 'yes']:\n",
    "                    print(\"Update aborted, if affirming update, please type 'Y' or 'Yes\")\n",
    "                    return\n",
    "            \n",
    "            ### check for new ids\n",
    "            self._check_for_new_ids(new_data, priors)\n",
    "            self.data = pd.concat([self.data, new_data], axis=0)\n",
    "            \n",
    "            self.data = self.data.sort_values(by='date').reset_index(drop=True)\n",
    "            self.data['rating_period'] = self.data.date.copy().rank(method='dense')\n",
    "            old_data = self.data.copy().loc[self.data['date']<oldest_date].reset_index(drop=True) \n",
    "            new_data = self.data.copy().loc[self.data['date']>=oldest_date].reset_index(drop=True)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            ### use rating period instead\n",
    "            oldest_rp = new_data.rating_period.min()\n",
    "            assert('rating_period' in list(new_data)), \"New data does not contain rating period or date column. Need one or the other to update.\"\n",
    "            print(f\"Oldest rating period in new data is {oldest_rp}, starting update from that rating period...\")\n",
    "\n",
    "            if affirm_update:\n",
    "                print(\"Proceed, Y/N?\")\n",
    "                proceed = input()\n",
    "                if proceed.lower() not in ['y', 'yes']:\n",
    "                    print(\"Update aborted, if affirming update, please type 'Y' or 'Yes\")\n",
    "                    return\n",
    "                \n",
    "            ### check for new ids\n",
    "            self._check_for_new_ids(new_data, priors)\n",
    "            self.data = pd.concat([self.data, new_data], axis=0)\n",
    "            self.data = self.data.sort_values(by='rating_period').reset_index(drop=True)\n",
    "            old_data = self.data.copy().loc[self.data['rating_period']<oldest_rp].reset_index(drop=True)\n",
    "            new_data = self.data.copy().loc[self.data['rating_period']>=oldest_rp].reset_index(drop=True)\n",
    "\n",
    "        ### convert ids to indices\n",
    "        new_data['protag_idx'] = new_data[self.protag_id].apply(lambda x: self.protag2index[x]).astype(int)\n",
    "        new_data['antag_idx'] = new_data[self.antag_id].apply(lambda x: self.protag2index[x]).astype(int)\n",
    "        new_data['stat_idx'] = new_data['stat'].apply(lambda x: self.stat2index[x]).astype(int)\n",
    "        self._add_k(data=new_data)\n",
    "        self._add_hfa(data=new_data)\n",
    "\n",
    "        assert(new_data[['protag_idx', 'antag_idx', 'stat_idx']].isnull().sum().sum()==0), \"Error converting ids to indices\"\n",
    "        ### reset ratings matrix to prior to new data\n",
    "        self._reset_ratings(old_data, priors)\n",
    "        ### update ratings\n",
    "        self.run_history(data=new_data, is_update=True)\n",
    "\n",
    "        return\n",
    "    \n",
    "    def predict(self, upcoming_matches, priors=None):\n",
    "\n",
    "        ### bunch of validation checks ###\n",
    "        assert(type(self.history) != str), \"Please run run_history() function before predicting\"\n",
    "        assert(type(upcoming_matches) == pd.DataFrame), \"upcoming_matches must be a pandas dataframe\"\n",
    "        assert(self.protag_id in list(upcoming_matches)), f\"upcoming_matches must contain a {self.protag_id} column, like in the original data\"\n",
    "        assert(self.antag_id in list(upcoming_matches)), f\"upcoming_matches must contain a {self.antag_id} column, like in the original data\"\n",
    "        assert('stat' in list(upcoming_matches)), f\"upcoming_matches must contain a stat column\"\n",
    "        col_names = list(upcoming_matches)\n",
    "        if 'date' in col_names:\n",
    "            ### use date\n",
    "            date_dtype = upcoming_matches.date.dtype\n",
    "            assert(is_datetime(date_dtype)), \"Date column must be of type datetime\"\n",
    "            oldest_date = upcoming_matches.date.min()\n",
    "            assert('date' in list(self.data)), \"Old data does not contain date column, new data does. Confused whether to use rating period or date.\"\n",
    "            if oldest_date < self.data.date.max():\n",
    "                print(f\"Warning: oldest date in new data is {oldest_date}, which is before the most recent date in the old data. This will result in a prediction using the old data. Consider chronological ordering of data.\")\n",
    "        else:\n",
    "            ### use rating period instead\n",
    "            assert('rating_period' in list(upcoming_matches)), \"New data does not contain rating period or date column. Need one or the other to update.\"\n",
    "            oldest_rp = upcoming_matches.rating_period.min()\n",
    "            if oldest_rp < self.data.rating_period.max():\n",
    "                print(f\"Warning: oldest rating period in new data is {oldest_rp}, which is before the most recent rating period in the old data. This will result in a prediction using the old data. Consider chronological ordering of data.\")\n",
    "\n",
    "        ### check that no new stats have been added\n",
    "        new_stats = set(upcoming_matches.stat.unique())\n",
    "        old_stats = set(self.stats)\n",
    "        new_stats = new_stats.difference(old_stats)\n",
    "        assert(len(new_stats)==0), f\"New stats found: {new_stats}. This class is not currently able to handle new stats added via update. Please re-initialize starting from beginning. Feel free to submit request to add this functionality\"\n",
    "\n",
    "        ### check that no new ids have been added\n",
    "        new_ids = set(upcoming_matches[self.protag_id].unique())\n",
    "        new_ids = new_ids.union(set(upcoming_matches[self.antag_id].unique()))\n",
    "        old_ids = set(self.protag_ids.union(self.antag_ids))\n",
    "        new_ids = new_ids.difference(old_ids)\n",
    "        print(f\"{len(new_ids)} new ids found.\")\n",
    "\n",
    "        if len(new_ids) > 0:\n",
    "            self._update_rating_matrix(new_ids, priors)\n",
    "        \n",
    "        ### run prediction\n",
    "        curr_ratings = self.current_ratings().rename(columns={'rating':'protag_rating'})\n",
    "        antag_curr_ratings = curr_ratings.copy().rename(columns={self.protag_id:self.antag_id, 'rating':'antag_rating'})\n",
    "\n",
    "        upcoming_matches = pd.merge(upcoming_matches, curr_ratings, on=self.protag_id, how='left')\n",
    "        upcoming_matches = pd.merge(upcoming_matches, antag_curr_ratings, on=self.antag_id, how='left')\n",
    "        upcoming_matches['rating_diff'] = upcoming_matches['protag_rating'] - upcoming_matches['antag_rating']\n",
    "        upcoming_matches['prob'] = upcoming_matches['rating_diff'].apply(lambda x: 1/(1+10**(-x/400)))\n",
    "        upcoming_matches['pred'] = upcoming_matches['prob'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "        return upcoming_matches\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbde6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f577f508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11036c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb9d6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d116fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656f107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360cde6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
