{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9a7ac1f",
   "metadata": {},
   "source": [
    "\n",
    "# Original Glicko\n",
    "\n",
    "The original Glicko system was created by Mark Glickman in 1995. You can read about it in detail on Mark Glickman's website http://glicko.net/. It was one of, if not the first attempts at incorporating uncertainty into a Elo-style ratings system. It often outperforms basic Elo for that reason, while keeping most of Elo's advantages. There are still very few parameters to tune, and it is still fairly universal, and it is computationally quick. While Glicko is generally outperformed by some more computationally intensive and new methods, it serves as a great baseline while rating player or team performance. \n",
    "\n",
    "Glicko 2 was developed later, and has an additional parameter. However, I haven't found much difference between the two.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- Quicker to converge than Elo\n",
    "- Better at updating once converged than Elo\n",
    "- Simplicity\n",
    "- Computational speed\n",
    "- Universality\n",
    "- Good at handling cross-league, cross-conference play\n",
    "- Not much tuning needed - the default RD of 350 usually gives you reasonable results, rarely is a much different value needed\n",
    "\n",
    "### Disadvantages\n",
    "\n",
    "- Cannot account for score difference. A win by 50 is the same as a win by 5.\n",
    "- There is no attempt to model style of play or player idiosyncracies\n",
    "- Without some edits, it will not put more weight on certain games than others, i.e., if a team or player is particularly motivated. \n",
    "- As with any rating system, if players are allowed to selectively choose opponents, it can ruin the fidelity of the ratings\n",
    "- Is meant for 1v1 ratings, or team v team. Cannot innately handle 1vMany or Many vs. Many.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b54d9be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Glicko' from 'oddsmaker.state_space' (C:\\Users\\Blake\\anaconda3\\lib\\site-packages\\oddsmaker\\state_space.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10020\\673066207.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0moddsmaker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_space\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGlicko\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_datetime64_any_dtype\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mis_datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Glicko' from 'oddsmaker.state_space' (C:\\Users\\Blake\\anaconda3\\lib\\site-packages\\oddsmaker\\state_space.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from copy import copy\n",
    "from tqdm import tqdm\n",
    "from oddsmaker.state_space import Glicko\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c004c734",
   "metadata": {},
   "source": [
    "\n",
    "## Quick Start\n",
    "\n",
    "Here, I'll show how you can use the oddsmaker Glicko class to model team ratings, and compare it to Elo. The class takes data in a specific format. Once you learn that format, it becomes powerful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f844114f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8397777 , 0.61403004],\n",
       "       [0.14504105, 0.89587469],\n",
       "       [0.42231017, 0.60442336]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test = np.random.random((4,3,2))\n",
    "\n",
    "test[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1fd698e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Glicko():\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    Glicko rating system implementation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pandas dataframe\n",
    "        Dataframe containing the following columns:\n",
    "            - protag_id: protagonist id (player or team)\n",
    "            - antag_id: antagonist id (player or team)\n",
    "            - stat: Specifies stat involved\n",
    "            - result: 0 for loss, 1 for win, 0.5 for tie\n",
    "            - is_home (optional): 1 for home, -1 for away, 0 for neutral\n",
    "            - date or rating period: date of game or rating period of game\n",
    "    protag_id : str, optional\n",
    "        Name of protagonist id column, by default 'team_name'\n",
    "    antag_id : str, optional    \n",
    "        Name of antagonist id column, by default 'opp_name' \n",
    "    result_col : str, optional\n",
    "        Name of result column, by default 'result'\n",
    "    RD : int, optional\n",
    "        Initial RD (sigma, or standard deviation) value, by default 350\n",
    "    max_RD : int, optional    \n",
    "        Maximum RD value, by default 350. Usually same as initial RD\n",
    "    time_param : float, optional\n",
    "        Time parameter, by default 1. Multiplies by time elapsed. The lower the value, the slower the rating variance goes back to default\n",
    "    hfa : int, float, or dict, optional\n",
    "        Home field advantage value(s) to use for each stat. Used to create 'hfa' column. If 'hfa' column already provided, then ignores. If int or float, applies to all stats. If dict, applies to each stat individually. If None, no home field advantage is used. Default is None.\n",
    "    priors : dict, optional\n",
    "        Dictionary of priors to use for each stat. If None, no priors are used. Default is None.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            data, \n",
    "            protag_id='protag', \n",
    "            antag_id='antag', \n",
    "            result_col='result', \n",
    "            RD=350, \n",
    "            max_RD=350, \n",
    "            time_param=1, \n",
    "            matchup_type='1v1',\n",
    "            hfa=None, \n",
    "            priors=None\n",
    "        ):\n",
    "\n",
    "        self.data = data.copy()\n",
    "        self.protag_id = protag_id\n",
    "        self.antag_id = antag_id\n",
    "        self.result_col = result_col\n",
    "        self.RD = RD\n",
    "        self.max_RD = max_RD\n",
    "        self.time_param = time_param\n",
    "        self.hfa = hfa\n",
    "        self.matchup_type = matchup_type\n",
    "        self.col_names = list(self.data)\n",
    "        self.col_names = [cn.lower().strip() for cn in self.col_names]\n",
    "        self.data.columns=self.col_names\n",
    "        \n",
    "        ## constant\n",
    "        self.q = np.log(10)/400\n",
    "\n",
    "        ### validation checks\n",
    "        assert(self.protag_id in list(data)), f\"{self.protag_id} not in columns, please specify team column name with protag_id argument\"\n",
    "        assert(self.antag_id in list(data)), f\"{self.antag_id} not in columns, please specify opponent column name with antag_id argument\"\n",
    "\n",
    "        assert('stat' in list(self.data)), 'No stat column, please add a stat name column to your data'\n",
    "        self.stats = sorted(list(self.data.stat.unique()))\n",
    "        self.result_col = result_col\n",
    "        assert(self.result_col in list(self.data)), 'Please include an outcome/result column, can specify the name with result col argument'\n",
    "        assert((('date' in self.col_names)|('rating_period' in self.col_names))), \"Need either a date column or a rating period column\"\n",
    "        if 'date' in self.col_names:\n",
    "            self.period_type = 'date'\n",
    "            assert(is_datetime(self.data[self.period_type].dtype)), \"Date column must be of type datetime\"\n",
    "        else:\n",
    "            self.period_type = 'rating_period'\n",
    "\n",
    "        assert(self.matchup_type in ['1v1','1vMany','ManyvMany','Multiple']), \"matchup_type must be one of ['1v1','1vMany','ManyvMany','Multiple']\"\n",
    "        if self.matchup_type == 'Multiple':\n",
    "            assert('matchup_type' in list(self.data)), \"matchup_type is set to 'Multiple', but no matchup_type column found in data\"\n",
    "            for mtype in self.data.matchup_type.unique():\n",
    "                assert(mtype in ['1v1','1vMany','ManyvMany']), \"Unrecognized matchup_type, must be one of ['1v1','1vMany','ManyvMany']\"\n",
    "        else:   \n",
    "            self.data['matchup_type'] = self.matchup_type\n",
    "\n",
    "        self.num_protags = len(self.data[self.protag_id].unique())\n",
    "        self.num_antags = len(self.data[self.antag_id].unique())\n",
    "        self.num_stats = len(self.data.stat.unique())\n",
    "        self.num_games = len(self.data)//2\n",
    "\n",
    "        self.rating_matrix = np.ones((self.num_protags, self.num_stats, 3))*1500\n",
    "        self.rating_matrix[:,:,1] = self.RD\n",
    "        self.rating_matrix[:,:,2] = 120 # default time off. Not used initially, so just placeholder\n",
    "\n",
    "        ### check if data is symmetrical, i.e., for every team a vs team b there is a team b vs team a\n",
    "        protags = self.data.groupby(['rating_period','stat'])[self.protag_id].apply(set).reset_index().copy()\n",
    "        antags =self.data.groupby(['rating_period','stat'])[self.antag_id].apply(set).reset_index().copy()\n",
    "        sym_test = protags.merge(antags, how='left', on=['rating_period','stat'])\n",
    "        sym_test['sym_diff'] = sym_test[[self.protag_id,self.antag_id]].apply(lambda x: len(x[self.protag_id].symmetric_difference(x[self.antag_id])), axis=1)\n",
    "        sym_val = sym_test['sym_diff'].mean()\n",
    "    \n",
    "        if sym_val > 0.05:\n",
    "            print(\"Warning: data is not symmetrical. There should be two rows per match for this class\")\n",
    "            raise ValueError(\" At least {}% of games are missing.\".format(round(100*sym_val,2)))\n",
    "        elif sym_val > 0:\n",
    "            print(\"Warning: a few games are likely missing their symmetrical partner.\")\n",
    "\n",
    "        ### index maps\n",
    "        self.protag2index = {}\n",
    "        for i,protag_id in enumerate(self.data[self.protag_id].unique()):\n",
    "            self.protag2index[protag_id] = i\n",
    "            \n",
    "        self.stat2index = {}\n",
    "        for j,stat in enumerate(self.stats):\n",
    "            self.stat2index[stat] = j\n",
    "            \n",
    "        if priors is not None:\n",
    "            self.priors = priors\n",
    "            assert(type(self.priors)==dict), \"priors must be a dictionary\"\n",
    "            self._implement_priors()\n",
    "\n",
    "        self._add_hfa()\n",
    "            \n",
    "        ### initialize ratings\n",
    "        self.data['protag_idx'] = self.data[self.protag_id].copy().map(self.protag2index)\n",
    "        self.data['antag_idx'] = self.data[self.antag_id].copy().map(self.protag2index)\n",
    "        self.data['stat_idx'] = self.data['stat'].copy().map(self.stat2index)\n",
    "\n",
    "\n",
    "    def _implement_priors(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Implements priors if they are provided\n",
    "        \"\"\"\n",
    "\n",
    "        for protag_id, stat_dict in self.priors.items():\n",
    "            assert(type(stat_dict)==dict), \"Each protag_id key in priors dict must be a dict of stat:rating pairs\"\n",
    "            for stat, rating_dict in stat_dict.items():\n",
    "                assert(stat in self.stats), f\"{stat} is not a stat in the dataset\"\n",
    "                assert('rating' in rating_dict), \"Each stat key in priors dict must have a 'rating' key\"\n",
    "                assert('RD' in rating_dict), \"Each stat key in priors dict must have a 'RD' key\"\n",
    "                self.rating_matrix[self.protag2index[protag_id], self.stat2index[stat], 0] = rating_dict['rating']\n",
    "                self.rating_matrix[self.protag2index[protag_id], self.stat2index[stat], 1] = rating_dict['RD']\n",
    "                if 'time_off' in rating_dict:\n",
    "                    self.rating_matrix[self.protag2index[protag_id], self.stat2index[stat], 2] = rating_dict['time_off']\n",
    "\n",
    "        return\n",
    "\n",
    "    def _add_hfa(self, new_data=False):\n",
    "\n",
    "        \"\"\"\n",
    "        Adds home field advantage to data if it is provided\n",
    "        \"\"\"\n",
    "\n",
    "        if self.hfa is None:\n",
    "            self.has_hfa=False\n",
    "            return\n",
    "    \n",
    "        if ((new_data == True)&('hfa' not in list(self.data))):\n",
    "            raise ValueError(\"hfa provided for original data, but no hfa column found in new data. Please add hfa column similar to previously provided data\")\n",
    "\n",
    "        if type(self.hfa)==dict:\n",
    "            self.data['hfa'] = self.data['stat'].map(self.hfa).copy()\n",
    "        elif type(self.hfa) in [int, float]:\n",
    "            self.data['hfa'] = self.hfa\n",
    "        else:\n",
    "            raise ValueError(\"hfa must be a dictionary, float, or an integer\")\n",
    "            \n",
    "        self.has_hfa=True\n",
    "\n",
    "        return\n",
    "\n",
    "    def _d_sq_calc(self, x):\n",
    "        return 1/(self.q**2 * (x.g_opps**2*(x.exp_res)*(1-x.exp_res)).sum())\n",
    "\n",
    "    def _mu_adj_calc(self, x):\n",
    "        return (x.g_opps*(x.result-x.exp_res)).sum()\n",
    "\n",
    "    def _rating_period_update(self, pregame_protag_ratings, pregame_antag_ratings, rp):\n",
    "\n",
    "        \"\"\"\n",
    "        Updates ratings for a single rating period\n",
    "        \"\"\"\n",
    "\n",
    "        protag_mus = pregame_protag_ratings[:,0]\n",
    "        protag_RDs = pregame_protag_ratings[:,1]\n",
    "\n",
    "        antag_mus = pregame_antag_ratings[:,0]\n",
    "        antag_RDs = pregame_antag_ratings[:,1]\n",
    "\n",
    "        g_opps = 1/np.sqrt(1+(3*self.q**2*antag_RDs**2)/np.pi**2)\n",
    "        exp_res = 1/(1+10**(-g_opps*(protag_mus-antag_mus)/400))\n",
    "\n",
    "        pids = rp['protag_idx'].values\n",
    "        aids = rp['antag_idx'].values\n",
    "        sids = rp['stat_idx'].values\n",
    "\n",
    "        temp_df = pd.DataFrame({\n",
    "            'pid':pids, \n",
    "            'stat':sids,\n",
    "            'mus':protag_mus,\n",
    "            'rds':protag_RDs,\n",
    "            'g_opps':g_opps,\n",
    "            'exp_res':exp_res,\n",
    "            'result':rp[self.result_col].values\n",
    "        })\n",
    "\n",
    "        d_sq = temp_df.groupby(['pid','stat']).apply(lambda x: self._d_sq_calc(x)).reset_index()\n",
    "        ids = d_sq[['pid','stat']]\n",
    "        d_sq = d_sq[0].values\n",
    "\n",
    "        # np.sum([g_opps[i]*(results[i]-exp_results[i]) for i in range(self.num_opps)])\n",
    "        mu_adj_term = temp_df.groupby(['pid','stat']).apply(lambda x: self._mu_adj_calc(x)).reset_index()\n",
    "        mu_adj_term = mu_adj_term[0].values\n",
    "        \n",
    "        print(protag_mus)\n",
    "        print(protag_RDs)\n",
    "        print(mu_adj_term)\n",
    "        single_data = temp_df.drop_duplicates(subset=['pid','stat'])[['pid','stat','mus','rds']]\n",
    "        single_data = ids.merge(single_data, how='left', on=['pid','stat'])\n",
    "        single_protag_mus = single_data['mus'].values\n",
    "        single_protag_RDs = single_data['rds'].values\n",
    "\n",
    "        new_protag_mus = single_protag_mus + self.q/(1/(single_protag_RDs**2) + 1/d_sq)*mu_adj_term\n",
    "        new_protag_RDs = np.sqrt(1/(1/(single_protag_RDs**2) + 1/d_sq))\n",
    "\n",
    "        postgame_protag_ratings = np.zeros(ids.shape)\n",
    "        postgame_protag_ratings[:,0] = new_protag_mus\n",
    "        postgame_protag_ratings[:,1] = new_protag_RDs\n",
    "\n",
    "        return postgame_protag_ratings\n",
    "\n",
    "    def create_pregame_ratings(self):\n",
    "\n",
    "        \"\"\"\n",
    "        Runs through all games in history and creates pregame ratings\n",
    "        \"\"\"\n",
    "\n",
    "        self.data = self.data.sort_values(by=[self.period_type,'stat']).reset_index(drop=True)\n",
    "\n",
    "        quick_iterator = self.data.groupby([self.period_type,'stat'])\n",
    "        for rp_index, rating_period in tqdm(quick_iterator, total=len(quick_iterator)):\n",
    "\n",
    "            pregame_protag_ratings = self.rating_matrix[rating_period.protag_idx.values, rating_period.stat_idx.values, :]\n",
    "            pregame_antag_ratings = self.rating_matrix[rating_period.antag_idx.values, rating_period.stat_idx.values, :]\n",
    "\n",
    "            if self.has_hfa:\n",
    "                pregame_protag_ratings = pregame_protag_ratings+((rating_period.hfa.values*rating_period.is_home.values)/2)\n",
    "                pregame_antag_ratings = pregame_antag_ratings-((rating_period.hfa.values*rating_period.is_home.values)/2)\n",
    "\n",
    "            postgame_protag_ratings = self._rating_period_update(pregame_protag_ratings, pregame_antag_ratings, rating_period.copy())\n",
    "\n",
    "            if self.has_hfa:\n",
    "                postgame_protag_ratings = pregame_protag_ratings-((rating_period.hfa.values*rating_period.is_home.values)/2)\n",
    "            print(postgame_protag_ratings)\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "13622a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 166.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1500. 1500. 1500. 1400. 1550. 1700.]\n",
      "[200. 200. 200.  30. 100. 300.]\n",
      "[-0.27202894 -0.32153156  0.37110077  0.23173759]\n",
      "[[1464.10646276  151.39890245]\n",
      " [1398.34251247   29.92509104]\n",
      " [1570.18760945   97.21172957]\n",
      " [1784.35028135  251.45899758]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def make_symmetrical(df, protag_id='protag', antag_id='antag'):\n",
    "    \n",
    "    antag_df = df.copy()\n",
    "    antag_df['result'] = 1-antag_df['result'].copy()\n",
    "    antag_df = antag_df.rename(columns={protag_id:antag_id, antag_id:protag_id})\n",
    "    \n",
    "    df = pd.concat([df, antag_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'rating_period':[1,1,1],\n",
    "    'protag':[1,1,1],\n",
    "    'antag':[2,3,4],\n",
    "    'stat':np.repeat('strokes_gained',3),\n",
    "    'result':[1,0,0]\n",
    "})\n",
    "\n",
    "data = make_symmetrical(data)\n",
    "\n",
    "priors = {\n",
    "    1:{'strokes_gained':{'rating':1500, 'RD':200}},\n",
    "    2:{'strokes_gained':{'rating':1400, 'RD':30}},\n",
    "    3:{'strokes_gained':{'rating':1550, 'RD':100}},\n",
    "    4:{'strokes_gained':{'rating':1700, 'RD':300}}\n",
    "}\n",
    "\n",
    "glicko = Glicko(data, priors=priors)\n",
    "glicko.create_pregame_ratings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08ca448",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "348111f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63946774, 0.61916545],\n",
       "       [0.43184235, 0.5       ],\n",
       "       [0.30284073, 0.38083455],\n",
       "       [0.5       , 0.61916545],\n",
       "       [0.30512404, 0.5       ],\n",
       "       [0.2225772 , 0.38083455],\n",
       "       [0.63946774, 0.61916545],\n",
       "       [0.43184235, 0.5       ],\n",
       "       [0.30284073, 0.38083455]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_protags = np.array([\n",
    "    [[1500, 200], [1600, 200]],\n",
    "    [[1500, 200], [1500, 200]],\n",
    "    [[1500, 200], [1400, 200]],\n",
    "    [[1400, 200], [1600, 200]],\n",
    "    [[1400, 200], [1500, 200]],\n",
    "    [[1400, 200], [1400, 200]],\n",
    "    [[1500, 150], [1600, 200]],\n",
    "    [[1500, 150], [1500, 200]],\n",
    "    [[1500, 150], [1400, 200]],\n",
    "])\n",
    "\n",
    "test_antags = np.array([\n",
    "    [[1400, 30], [1500, 200]],\n",
    "    [[1550, 100], [1500, 200]],\n",
    "    [[1700, 300], [1500, 200]],\n",
    "    [[1400, 30], [1500, 200]],\n",
    "    [[1550, 100], [1500, 200]],\n",
    "    [[1700, 300], [1500, 200]],\n",
    "    [[1400, 30], [1500, 200]],\n",
    "    [[1550, 100], [1500, 200]],\n",
    "    [[1700, 300], [1500, 200]],\n",
    "])\n",
    "\n",
    "test_protags.shape\n",
    "\n",
    "protag_mus = test_protags[:,:,0]\n",
    "protag_rds = test_protags[:,:,1]\n",
    "antag_mus = test_antags[:,:,0]\n",
    "antag_rds = test_antags[:,:,1]\n",
    "\n",
    "\n",
    "q=np.log(10)/400\n",
    "g_opps = 1/np.sqrt((1+(3*q**2)*(antag_rds**2)/np.pi**2))\n",
    "exp_res = 1/(1+10**((-g_opps*(protag_mus-antag_mus))/400))\n",
    "exp_res\n",
    "\n",
    "# len(stats)\n",
    "# stats\n",
    "#d_sq = 1/(q**2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcbe75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_sq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "01f7a91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mu</th>\n",
       "      <th>rd</th>\n",
       "      <th>g_opps</th>\n",
       "      <th>exp_res</th>\n",
       "      <th>pid</th>\n",
       "      <th>stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.995498</td>\n",
       "      <td>0.639468</td>\n",
       "      <td>1</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.619165</td>\n",
       "      <td>1</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.953149</td>\n",
       "      <td>0.431842</td>\n",
       "      <td>1</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.724235</td>\n",
       "      <td>0.302841</td>\n",
       "      <td>1</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.380835</td>\n",
       "      <td>1</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.995498</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.619165</td>\n",
       "      <td>2</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.953149</td>\n",
       "      <td>0.305124</td>\n",
       "      <td>2</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.724235</td>\n",
       "      <td>0.222577</td>\n",
       "      <td>2</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.380835</td>\n",
       "      <td>2</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.995498</td>\n",
       "      <td>0.639468</td>\n",
       "      <td>3</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1600</td>\n",
       "      <td>1600</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.619165</td>\n",
       "      <td>3</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.953149</td>\n",
       "      <td>0.431842</td>\n",
       "      <td>3</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>0.724235</td>\n",
       "      <td>0.302841</td>\n",
       "      <td>3</td>\n",
       "      <td>driving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td>0.844281</td>\n",
       "      <td>0.380835</td>\n",
       "      <td>3</td>\n",
       "      <td>irons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mu    rd    g_opps   exp_res  pid     stat\n",
       "0   1500  1500  0.995498  0.639468    1  driving\n",
       "1   1600  1600  0.844281  0.619165    1    irons\n",
       "2   1500  1500  0.953149  0.431842    1  driving\n",
       "3   1500  1500  0.844281  0.500000    1    irons\n",
       "4   1500  1500  0.724235  0.302841    1  driving\n",
       "5   1400  1400  0.844281  0.380835    1    irons\n",
       "6   1400  1400  0.995498  0.500000    2  driving\n",
       "7   1600  1600  0.844281  0.619165    2    irons\n",
       "8   1400  1400  0.953149  0.305124    2  driving\n",
       "9   1500  1500  0.844281  0.500000    2    irons\n",
       "10  1400  1400  0.724235  0.222577    2  driving\n",
       "11  1400  1400  0.844281  0.380835    2    irons\n",
       "12  1500  1500  0.995498  0.639468    3  driving\n",
       "13  1600  1600  0.844281  0.619165    3    irons\n",
       "14  1500  1500  0.953149  0.431842    3  driving\n",
       "15  1500  1500  0.844281  0.500000    3    irons\n",
       "16  1500  1500  0.724235  0.302841    3  driving\n",
       "17  1400  1400  0.844281  0.380835    3    irons"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pids = np.repeat(np.array([1,1,1,2,2,2,3,3,3]),2)\n",
    "stats = list(np.tile(['driving','irons'],9))\n",
    "temp_df = pd.DataFrame({\n",
    "    'mu':protag_mus.reshape(-1),\n",
    "    'rd':protag_mus.reshape(-1),\n",
    "    'g_opps':g_opps.reshape(-1),\n",
    "    'exp_res':exp_res.reshape(-1),\n",
    "    'pid':pids,\n",
    "    'stat':stats\n",
    "})\n",
    "temp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f63328d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([53685.74290198, 58670.26196183, 56817.55104186, 58670.26196183,\n",
       "       53685.74290198, 58670.26196183])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def d_sq_calc(x):\n",
    "    return 1/(q**2 * (x.g_opps**2*(x.exp_res)*(1-x.exp_res)).sum())\n",
    "d_sq = temp_df.groupby(['pid','stat']).apply(lambda x: d_sq_calc(x)).reset_index()\n",
    "ids = d_sq[['pid','stat']].values\n",
    "d_sq = d_sq[0].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a27fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def d_sq_calc(x):\n",
    "    return 1/(q**2 * (x.g_opps**2*(x.exp_res)*(1-x.exp_res)).sum())\n",
    "\n",
    "d_sq = temp_df.groupby('pid').apply(lambda x: d_sq_calc(x))\n",
    "protag_ids = d_sq.index.values\n",
    "d_sq = d_sq.values\n",
    "\n",
    "\n",
    "# self.player_a.mu = self.player_a.mu + (self.q/(1/self.player_a.rd**2+1/d_sq)*np.sum([g_opps[i]*(results[i]-exp_results[i]) for i in range(self.num_opps)]))\n",
    "# self.player_a.rd = np.sqrt(1/(1/self.player_a.rd**2 + 1/d_sq))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "79147a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_sq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9a2a6e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [200],\n",
       "       [150],\n",
       "       [200],\n",
       "       [150],\n",
       "       [200],\n",
       "       [150],\n",
       "       [200]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### may have to drop duplicates to get these but possible\n",
    "\n",
    "pmu_1d = np.array([1500, 1600, ])\n",
    "prd_1d = protag_rds.reshape(-1,1)\n",
    "# new_pmu = pmu_1d + (q/(1/))\n",
    "prd_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d35928f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protag_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f43a5277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1599.57187889, 1581.564999  ],\n",
       "       [1680.72617651, 1332.23662836],\n",
       "       [1688.09097059, 1611.23380995],\n",
       "       [1592.79405142, 1485.79695658]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "protag_mus = np.random.random((4,2))*400+1300\n",
    "\n",
    "\n",
    "protag_mus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "296a54a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "protag_rds = np.random.random((4,2))*100+250\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5760675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1492.28885754, 1571.34876168],\n",
       "       [1691.84871914, 1696.61314767],\n",
       "       [1529.69218904, 1663.54154893],\n",
       "       [1322.19870591, 1505.5040629 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "antag_mus = np.random.random((4,2))*400+1300\n",
    "antag_mus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3776667d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[261.01313845, 288.59590174],\n",
       "       [300.86893221, 325.89439742],\n",
       "       [318.84359453, 332.82385098],\n",
       "       [316.50336572, 269.32448527]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "antag_rds = np.random.random((4,2))*100+250\n",
    "antag_rds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f82ac5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=np.log(10)/400\n",
    "g_opps = 1/np.sqrt((1+(3*q**2)*(antag_rds**2)/np.pi**2))\n",
    "exp_res = 1/(1+10**((-g_opps*(protag_mus-antag_mus))/400))\n",
    "# g_opps.append(g_opp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e63c6617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.round(np.random.random((4,2)))\n",
    "results = results.astype(int)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de764a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61670547, 0.51084024],\n",
       "       [0.48842546, 0.18877934],\n",
       "       [0.65496187, 0.44843158],\n",
       "       [0.75006736, 0.47845482]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# new_mus = protag_mus + (q/(1/protag_rds**2+1/d_sq)*np.sum([g_opps[i]*(results[i]-exp_results[i]) for i in range(self.num_opps)]))\n",
    "# new_rds = np.sqrt(1/(1/protag_rds**2 + 1/d_sq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f609a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a501d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866dc221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7376d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23533730",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
