{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PageRank\n",
    "\n",
    "Developed by Larry Page and the backbone of Google, PageRank was initially applied to web pages and the links between them. In some cases, PageRank can also be a good ratings system in sports. I have found it does well in One vs. Many applications, like a golf tournament. I've added a way to implement time decay with it as well. Uniquely among rating systems, it also can be used to give a measure of entropy and uncertainty. There is a major limitation in my implementation however. In most cases, you'll want to also adjust for things like home/away and weather. PageRank doesn't have a great way to deal with that, other than using other computational methods to estimate the effects and then applying weights to your PageRank data. Yet still, I've found there are some niche applications where there are little other effects, like esports and already adjusted golf strokes gained data, where PageRank is very competitive. \n",
    "\n",
    "### Advantages\n",
    "- Simplicity, intuitiveness \n",
    "- Computational Speed\n",
    "- Can measure entropy\n",
    "- Can account for score difference\n",
    "- Can handle any number of opponents\n",
    "- Can scale as big as you need\n",
    "\n",
    "### Disadvantages\n",
    "- Need to keep number of players/teams constant or else ratings change scale\n",
    "- No innate way to adjust for meta factors\n",
    "- Not robust to param choices, and defaults aren't obvious because they depend on scale of scoring and number of teams\n",
    "- Need separate logic for differences and totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def optimize(self):\n",
    "        raise NotImplementedError(\"Subclasses must implement the optimize method.\")\n",
    "    \n",
    "class PageRankOptimizer(Optimizer):\n",
    "    def __init__(self, protag_col='team', antag_col='opponent', stat_col='score', static_protag_number=200, method='pagerank', time_decay=True):\n",
    "        super().__init__()\n",
    "        self.protag_col = protag_col\n",
    "        self.antag_col = antag_col\n",
    "        assert(protag_col != antag_col), \"Protagonist and Antagonist columns must be different\"\n",
    "        self.stat_col = stat_col\n",
    "        self.time_decay = time_decay\n",
    "        self.static_protag_number = static_protag_number\n",
    "        assert(method in ['pagerank', 'sparse', 'power_iteration']), \"Method not recognized\"\n",
    "        self.method = method\n",
    "\n",
    "    def load_data(self, data, path=None):\n",
    "        if path is not None:\n",
    "            self.data = pd.read_csv(path)\n",
    "        else:\n",
    "            self.data = data\n",
    "        self.preprocess_data()\n",
    "        \n",
    "    def preprocess_data(self):\n",
    "        assert(self.protag_col in self.data.columns), \"Protagonist column not found in data\"\n",
    "        assert(self.antag_col in self.data.columns), \"Antagonist column not found in data\"\n",
    "        assert(self.stat_col in self.data.columns), \"Stat column not found in data\"\n",
    "        assert('num_opponents' in self.data.columns), \"Number of opponents column not found in data\"\n",
    "\n",
    "        # Convert date column to datetime if needed\n",
    "        if isinstance(self.data['date'].iloc[0], str):\n",
    "            self.data['date'] = pd.to_datetime(self.data['date'])\n",
    "\n",
    "        # Sort data by date\n",
    "        self.data = self.data.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "        assert(len(self.data)>200), \"Not enough data to optimize\"\n",
    "\n",
    "    def pagerank(self, A, l2):\n",
    "\n",
    "        num_protags = A.shape[0]\n",
    "        b = np.random.rand(num_protags,1)\n",
    "        b = b/np.linalg.norm(b, 1)\n",
    "        for i in range(50):\n",
    "            b = l2 * A@b + (1-l2)/num_protags\n",
    "\n",
    "        return b\n",
    "\n",
    "    def pagerank_sparse(self, A, l2):\n",
    "        \n",
    "        A = csr_matrix(A)\n",
    "        num_protags = A.shape[0]\n",
    "        b = np.random.rand(num_protags,1)\n",
    "        b = b/np.linalg.norm(b, 1)\n",
    "        for i in range(50):\n",
    "            b = l2 * A@b + (1-l2)/num_protags\n",
    "\n",
    "        return b\n",
    "\n",
    "    def pagerank_power_iteration(self, A, l2, b, p_iter=25):\n",
    "        num_protags = A.shape[0]\n",
    "        for i in range(p_iter):\n",
    "            for j in range(num_protags):\n",
    "                b[j] = (1-l2)/num_protags+l2*np.sum(A[k][j]*b[k] for k in range(num_protags))\n",
    "        return A, b\n",
    "    \n",
    "    def run_history(self, halflife, l2, record_dates, return_entropy=False):\n",
    "\n",
    "        ratings = []\n",
    "\n",
    "        decay = np.exp(-np.log(2)/halflife)\n",
    "        A = np.zeros((self.static_protag_number, self.static_protag_number))\n",
    "        A_inv = np.zeros((self.static_protag_number, self.static_protag_number))\n",
    "        last_date = self.data['date'].iloc[0]\n",
    "\n",
    "        if self.method == 'power_iteration':\n",
    "            # need to initialize ratings\n",
    "            rtgs = np.random.rand(self.static_protag_number, 1)\n",
    "            rtgs_inv = np.random.rand(self.static_protag_number, 1)\n",
    "        \n",
    "        for date, day_df in tqdm(self.data.groupby(['date']), total=len(self.data['date'].unique())):\n",
    "            \n",
    "            ## decay ratings matrices\n",
    "            days_ago = (date-last_date).days\n",
    "            A = A * decay**days_ago\n",
    "            A_inv = A_inv * decay**days_ago\n",
    "            last_date = date\n",
    "\n",
    "            ## first update ratings\n",
    "            if date in record_dates:\n",
    "                # if date requested, calculate ratings\n",
    "                if self.method == 'pagerank':\n",
    "                    rtgs = self.pagerank(A, l2)\n",
    "                    rtgs_inv = self.pagerank(A_inv, l2)\n",
    "                elif self.method == 'sparse':\n",
    "                    rtgs = self.pagerank_sparse(A, l2)\n",
    "                    rtgs_inv = self.pagerank_sparse(A_inv, l2)\n",
    "                elif self.method == 'power_iteration':\n",
    "                    A, rtgs = self.pagerank_power_iteration(A, l2, rtgs)\n",
    "                    A_inv, rtgs_inv = self.pagerank_power_iteration(A_inv, l2, rtgs_inv)\n",
    "                rtg_df = pd.DataFrame({self.protag_col: [protag_map_inv[i] for i in range(self.static_protag_number)], 'rating': rtgs.reshape(-1)})\n",
    "                inv_rtg_df = pd.Series(rtgs_inv.reshape(-1), name='inv_rating')\n",
    "                rtg_df = pd.concat([rtg_df, inv_rtg_df], axis=1)\n",
    "                to_append = day_df.merge(rtg_df, on=self.protag_col)\n",
    "                rtg_df = rtg_df.rename(columns={self.protag_col: self.antag_col, 'rating': 'antag_rtg', 'inv_rating': 'inv_antag_rtg'})\n",
    "                to_append = to_append.merge(rtg_df, on=self.antag_col)\n",
    "                ratings.append(to_append)\n",
    "\n",
    "            # then use results to update rating matrix\n",
    "            protags = self.data[self.protag_col].value_counts()[:self.static_protag_number]\n",
    "            protag_map = {protag: i for i, protag in enumerate(protags.index)}\n",
    "            protag_map_inv = {i: protag for i, protag in enumerate(protags.index)}\n",
    "            day_df = day_df[day_df[self.protag_col].isin(protags.index)]\n",
    "            day_df = day_df[day_df[self.antag_col].isin(protags.index)]\n",
    "            day_df['protag_idx'] = day_df[self.protag_col].map(protag_map)\n",
    "            day_df['antag_idx'] = day_df[self.antag_col].map(protag_map)\n",
    "            ## positive only is more stable\n",
    "            day_df['stat'] = pd.DataFrame({\n",
    "                self.stat_col: day_df[self.stat_col],\n",
    "                'zero_max': np.zeros(len(day_df))\n",
    "            }).max(axis=1)\n",
    "            day_df['stat'] /= day_df['num_opponents']\n",
    "            A[day_df['protag_idx'], day_df['antag_idx']] += day_df[self.stat_col]\n",
    "            A_inv[day_df['antag_idx'], day_df['protag_idx']] += day_df[self.stat_col]\n",
    "\n",
    "\n",
    "        ratings = pd.concat(ratings, axis=0).reset_index(drop=True)\n",
    "        ratings['rating'] = ratings['rating'] - ratings['inv_rating']\n",
    "        ratings['opp_rating'] = ratings['antag_rtg'] - ratings['inv_antag_rtg']\n",
    "        ratings = ratings.drop(columns=['inv_rating', 'inv_antag_rtg', 'antag_rtg'])\n",
    "        return ratings\n",
    "\n",
    "    \n",
    "    def run_time_opt(self, init_points=10, n_iter=30, num_test_dates=20, halflife_bounds=(10, 800), l2_bounds=(1e-9, 10)):\n",
    "\n",
    "        # Select random test dates\n",
    "        unique_dates = self.data['date'].unique()\n",
    "        assert(len(self.data)>200), \"Not enough data to optimize\"\n",
    "        ## don't take from the first 10 or so dates\n",
    "        unique_dates = sorted(unique_dates)[10:]\n",
    "\n",
    "        test_dates = np.random.choice(unique_dates, size=num_test_dates, replace=False)\n",
    "        num_dates = len(unique_dates)\n",
    "\n",
    "        pbounds = {'halflife': halflife_bounds, 'l2': l2_bounds}\n",
    "\n",
    "        def time_bayes_objective(halflife, l2):\n",
    "            \n",
    "            ratings = self.run_history(halflife==halflife, l2=l2, record_dates=test_dates)\n",
    "            X = ratings[['rating','opp_rating']]\n",
    "            y = ratings[self.stat_col]\n",
    "            lr = LinearRegression()\n",
    "            lr.fit(X, y)\n",
    "            preds = lr.predict(X)\n",
    "            mse = mean_squared_error(y, preds)\n",
    "\n",
    "            if ratings['rating'].max() > 1e10:\n",
    "                return -1e10\n",
    "            return -mse\n",
    "\n",
    "        # Initialize the Bayesian Optimization object\n",
    "        optimizer = BayesianOptimization(f=time_bayes_objective, pbounds=pbounds, random_state=17)\n",
    "\n",
    "        # Perform the optimization\n",
    "        optimizer.maximize(init_points=init_points, n_iter=n_iter)\n",
    "        \n",
    "        # Get the best parameters and correlation\n",
    "        best_params = optimizer.max['params']\n",
    "        print(best_params)\n",
    "        best_halflife = best_params['halflife']\n",
    "        best_l2 = best_params['l2']\n",
    "        best_mse = -optimizer.max['target']\n",
    "\n",
    "        return best_halflife, best_l2, best_mse\n",
    "    \n",
    "    def get_ratings_for_dates(self, dates, l2, halflife=250, stat_type='diff', return_entropy=False):\n",
    "        dates = pd.to_datetime(dates)\n",
    "        dates = sorted(dates)\n",
    "\n",
    "        ## pagerank it is easier to just run entire history\n",
    "        return self.run_history(halflife, l2, dates, return_entropy=return_entropy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972312513520695"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "halflife = 250\n",
    "np.exp(-np.log(2)/halflife)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>team_score</th>\n",
       "      <th>opp_score</th>\n",
       "      <th>is_home</th>\n",
       "      <th>numot</th>\n",
       "      <th>team_fgm</th>\n",
       "      <th>team_fga</th>\n",
       "      <th>team_fgm3</th>\n",
       "      <th>team_fga3</th>\n",
       "      <th>team_ftm</th>\n",
       "      <th>...</th>\n",
       "      <th>opp_ast</th>\n",
       "      <th>opp_to</th>\n",
       "      <th>opp_stl</th>\n",
       "      <th>opp_blk</th>\n",
       "      <th>opp_pf</th>\n",
       "      <th>team_name</th>\n",
       "      <th>opp_name</th>\n",
       "      <th>date</th>\n",
       "      <th>score_diff</th>\n",
       "      <th>num_opponents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>68</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>Penn</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>84</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>Penn St</td>\n",
       "      <td>MD E Shore</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>71</td>\n",
       "      <td>87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>70</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>Pepperdine</td>\n",
       "      <td>California</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>-16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>SMU</td>\n",
       "      <td>Jacksonville St</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>67</td>\n",
       "      <td>94</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>Princeton</td>\n",
       "      <td>Duquesne</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>-27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  team_score  opp_score  is_home  numot  team_fgm  team_fga  \\\n",
       "0    2020          81         80       -1      0        29        68   \n",
       "1    2020          84         46        1      0        29        58   \n",
       "2    2020          71         87       -1      0        26        70   \n",
       "3    2020          74         65        1      0        26        60   \n",
       "4    2020          67         94       -1      0        27        57   \n",
       "\n",
       "   team_fgm3  team_fga3  team_ftm  ...  opp_ast  opp_to  opp_stl  opp_blk  \\\n",
       "0          8         26        15  ...       10      19       10        5   \n",
       "1         12         31        14  ...        8      19        7        1   \n",
       "2         10         29         9  ...       12      12        4        1   \n",
       "3          5         21        17  ...       12      19        7        3   \n",
       "4          7         22         6  ...       13       8       10        5   \n",
       "\n",
       "   opp_pf   team_name         opp_name       date  score_diff  num_opponents  \n",
       "0      18        Penn          Alabama 2019-11-05           1              1  \n",
       "1      22     Penn St       MD E Shore 2019-11-05          38              1  \n",
       "2      13  Pepperdine       California 2019-11-05         -16              1  \n",
       "3      19         SMU  Jacksonville St 2019-11-05           9              1  \n",
       "4      15   Princeton         Duquesne 2019-11-05         -27              1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_path = '../data'\n",
    "sample_data = pd.read_csv(os.path.join(data_path, 'testing', 'ncaam_sample_data.csv'))\n",
    "sample_data['score_diff'] = sample_data['team_score'] - sample_data['opp_score']\n",
    "sample_data['date'] = pd.to_datetime(sample_data['date'])\n",
    "sample_data = sample_data.sort_values('date')\n",
    "sample_data = sample_data.loc[sample_data['date'] > '2019-10-01'].reset_index(drop=True)\n",
    "sample_data['num_opponents'] = 1\n",
    "sample_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PO = PageRankOptimizer(\n",
    "    protag_col='team_name', \n",
    "    antag_col='opp_name', \n",
    "    stat_col='score_diff', \n",
    "    static_protag_number=sample_data['team_name'].nunique()\n",
    ")\n",
    "\n",
    "PO.load_data(sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 151.07it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rtgs_history = PO.get_ratings_for_dates(sample_data.date.unique()[-100:], l2=0.8/sample_data.team_name.nunique(), halflife=250, stat_type='diff', return_entropy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | halflife  |    l2     |\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 185.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m1        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m242.8    \u001b[0m | \u001b[0m5.306    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 171.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m2        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m161.3    \u001b[0m | \u001b[0m0.679    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 183.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m3        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m631.7    \u001b[0m | \u001b[0m6.563    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 184.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m4        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m513.6    \u001b[0m | \u001b[0m5.756    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 179.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m5        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m40.86    \u001b[0m | \u001b[0m3.578    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 187.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m6        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m757.1    \u001b[0m | \u001b[0m0.6004   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 180.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m7        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m692.6    \u001b[0m | \u001b[0m8.773    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 180.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m8        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m50.44    \u001b[0m | \u001b[0m6.524    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 184.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m9        \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m445.9    \u001b[0m | \u001b[0m5.975    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 178.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m10       \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m392.0    \u001b[0m | \u001b[0m2.83     \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 187.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m11       \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m799.9    \u001b[0m | \u001b[0m9.719    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 180.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m12       \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m10.06    \u001b[0m | \u001b[0m8.649    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 181.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m13       \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m800.0    \u001b[0m | \u001b[0m0.8699   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 187.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m14       \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m11.46    \u001b[0m | \u001b[0m0.1539   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 179.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m15       \u001b[0m | \u001b[0m-1e+10   \u001b[0m | \u001b[0m765.8    \u001b[0m | \u001b[0m5.588    \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "  2%|▏         | 9/381 [00:00<00:01, 188.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m halflife, l2, mse \u001b[38;5;241m=\u001b[39m PO\u001b[38;5;241m.\u001b[39mrun_time_opt(init_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, num_test_dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m, halflife_bounds\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m800\u001b[39m), l2_bounds\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1e-9\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n",
      "Cell \u001b[1;32mIn[37], line 168\u001b[0m, in \u001b[0;36mPageRankOptimizer.run_time_opt\u001b[1;34m(self, init_points, n_iter, num_test_dates, halflife_bounds, l2_bounds)\u001b[0m\n\u001b[0;32m    165\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m BayesianOptimization(f\u001b[38;5;241m=\u001b[39mtime_bayes_objective, pbounds\u001b[38;5;241m=\u001b[39mpbounds, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m17\u001b[39m)\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# Perform the optimization\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mmaximize(init_points\u001b[38;5;241m=\u001b[39minit_points, n_iter\u001b[38;5;241m=\u001b[39mn_iter)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Get the best parameters and correlation\u001b[39;00m\n\u001b[0;32m    171\u001b[0m best_params \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mmax[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:310\u001b[0m, in \u001b[0;36mBayesianOptimization.maximize\u001b[1;34m(self, init_points, n_iter, acquisition_function, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    308\u001b[0m     x_probe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuggest(util)\n\u001b[0;32m    309\u001b[0m     iteration \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprobe(x_probe, lazy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer \u001b[38;5;129;01mand\u001b[39;00m iteration \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;66;03m# The bounds transformer should only modify the bounds after\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;66;03m# the init_points points (only for the true iterations)\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_bounds(\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bounds_transformer\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space))\n",
      "File \u001b[1;32mc:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\bayes_opt\\bayesian_optimization.py:208\u001b[0m, in \u001b[0;36mBayesianOptimization.probe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue\u001b[38;5;241m.\u001b[39madd(params)\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_space\u001b[38;5;241m.\u001b[39mprobe(params)\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch(Events\u001b[38;5;241m.\u001b[39mOPTIMIZATION_STEP)\n",
      "File \u001b[1;32mc:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\bayes_opt\\target_space.py:236\u001b[0m, in \u001b[0;36mTargetSpace.probe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    234\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_as_array(params)\n\u001b[0;32m    235\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys, x))\n\u001b[1;32m--> 236\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constraint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregister(x, target)\n",
      "Cell \u001b[1;32mIn[37], line 152\u001b[0m, in \u001b[0;36mPageRankOptimizer.run_time_opt.<locals>.time_bayes_objective\u001b[1;34m(halflife, l2)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtime_bayes_objective\u001b[39m(halflife, l2):\n\u001b[1;32m--> 152\u001b[0m     ratings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_history(halflife\u001b[38;5;241m==\u001b[39mhalflife, l2\u001b[38;5;241m=\u001b[39ml2, record_dates\u001b[38;5;241m=\u001b[39mtest_dates)\n\u001b[0;32m    153\u001b[0m     X \u001b[38;5;241m=\u001b[39m ratings[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopp_rating\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m    154\u001b[0m     y \u001b[38;5;241m=\u001b[39m ratings[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstat_col]\n",
      "Cell \u001b[1;32mIn[37], line 126\u001b[0m, in \u001b[0;36mPageRankOptimizer.run_history\u001b[1;34m(self, halflife, l2, record_dates, return_entropy)\u001b[0m\n\u001b[0;32m    121\u001b[0m     day_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstat_col: day_df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstat_col],\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzero_max\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(day_df))\n\u001b[0;32m    124\u001b[0m     })\u001b[38;5;241m.\u001b[39mmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    125\u001b[0m     day_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m day_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_opponents\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 126\u001b[0m     A[day_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprotag_idx\u001b[39m\u001b[38;5;124m'\u001b[39m], day_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mantag_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m day_df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstat_col]\n\u001b[0;32m    127\u001b[0m     A_inv[day_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mantag_idx\u001b[39m\u001b[38;5;124m'\u001b[39m], day_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprotag_idx\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m day_df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstat_col]\n\u001b[0;32m    130\u001b[0m ratings \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(ratings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3758\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3755\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns)):\n\u001b[0;32m   3756\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_column_array(i)\n\u001b[1;32m-> 3758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   3759\u001b[0m     check_deprecated_indexers(key)\n\u001b[0;32m   3760\u001b[0m     key \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(key)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "halflife, l2, mse = PO.run_time_opt(init_points=10, n_iter=30, num_test_dates=60, halflife_bounds=(10, 800), l2_bounds=(1e-9, 1e-2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/381 [00:00<?, ?it/s]c:\\Users\\Blake\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1178: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for obj in iterable:\n",
      "100%|██████████| 381/381 [00:02<00:00, 149.92it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "rtgs_history = PO.get_ratings_for_dates(sample_data.date.unique()[-100:], l2=l2, halflife=halflife, stat_type='diff', return_entropy=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_name</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Baylor</td>\n",
       "      <td>6.668578e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Louisiana Tech</td>\n",
       "      <td>5.514692e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>4.963387e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>St Mary's CA</td>\n",
       "      <td>4.660335e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>SMU</td>\n",
       "      <td>4.614773e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>MS Valley St</td>\n",
       "      <td>4.324825e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ark Pine Bluff</td>\n",
       "      <td>4.077192e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Houston Chr</td>\n",
       "      <td>3.699619e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>St Louis</td>\n",
       "      <td>3.234831e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>Grand Canyon</td>\n",
       "      <td>3.139403e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>Tulane</td>\n",
       "      <td>2.994272e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Texas A&amp;M</td>\n",
       "      <td>2.498596e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>North Texas</td>\n",
       "      <td>2.493928e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>2.490845e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Toledo</td>\n",
       "      <td>2.307800e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>New Mexico St</td>\n",
       "      <td>2.169871e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>2.149118e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Portland</td>\n",
       "      <td>2.098135e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>2.088547e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Dayton</td>\n",
       "      <td>2.079262e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Florida A&amp;M</td>\n",
       "      <td>2.045320e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>1.978851e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Murray St</td>\n",
       "      <td>1.935148e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>CS Sacramento</td>\n",
       "      <td>1.927959e+134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Mississippi St</td>\n",
       "      <td>1.924424e+134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          team_name         rating\n",
       "20           Baylor  6.668578e+134\n",
       "149  Louisiana Tech  5.514692e+134\n",
       "0       Abilene Chr  4.963387e+134\n",
       "280    St Mary's CA  4.660335e+134\n",
       "254             SMU  4.614773e+134\n",
       "156    MS Valley St  4.324825e+134\n",
       "12   Ark Pine Bluff  4.077192e+134\n",
       "115     Houston Chr  3.699619e+134\n",
       "279        St Louis  3.234831e+134\n",
       "106    Grand Canyon  3.139403e+134\n",
       "303          Tulane  2.994272e+134\n",
       "297       Texas A&M  2.498596e+134\n",
       "209     North Texas  2.493928e+134\n",
       "58         Colorado  2.490845e+134\n",
       "300          Toledo  2.307800e+134\n",
       "200   New Mexico St  2.169871e+134\n",
       "264         Seattle  2.149118e+134\n",
       "231        Portland  2.098135e+134\n",
       "219        Oklahoma  2.088547e+134\n",
       "67           Dayton  2.079262e+134\n",
       "90      Florida A&M  2.045320e+134\n",
       "293       Tennessee  1.978851e+134\n",
       "185       Murray St  1.935148e+134\n",
       "39    CS Sacramento  1.927959e+134\n",
       "175  Mississippi St  1.924424e+134"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings = rtgs_history.groupby(['team_name'])[['rating']].last().copy().reset_index()\n",
    "test_ratings.sort_values(by=['rating'], ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
